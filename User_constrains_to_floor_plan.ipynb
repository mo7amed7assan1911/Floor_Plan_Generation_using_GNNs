{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7edfe0a6",
   "metadata": {
    "papermill": {
     "duration": 0.008886,
     "end_time": "2023-04-16T07:04:27.220632",
     "exception": false,
     "start_time": "2023-04-16T07:04:27.211746",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Planify - User constrains to floor plan\n",
    "\n",
    "### Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#intro\">Introduction</a></li>\n",
    "    <ul>\n",
    "        <li><a href=\"#Imports\">Imports</a></li>\n",
    "        <li><a href=\"#func\">Functions used</a></li>\n",
    "    </ul>\n",
    "<li><a href=\"#wrangling\">Data Wrangling</a></li>\n",
    "<li><a href=\"#model\">GNN Model</a></li>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c40f6938",
   "metadata": {
    "papermill": {
     "duration": 0.007171,
     "end_time": "2023-04-16T07:04:27.235516",
     "exception": false,
     "start_time": "2023-04-16T07:04:27.228345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "> This notebook getting garphs in the Networkx format from the `Creating Graphs` notebook. And its main goal is to make the GNN model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0700caf5",
   "metadata": {
    "papermill": {
     "duration": 0.007268,
     "end_time": "2023-04-16T07:04:27.276656",
     "exception": false,
     "start_time": "2023-04-16T07:04:27.269388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='Imports'></a>\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "bdec8865",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-16T07:05:00.966534Z",
     "iopub.status.busy": "2023-04-16T07:05:00.966170Z",
     "iopub.status.idle": "2023-04-16T07:05:04.594842Z",
     "shell.execute_reply": "2023-04-16T07:05:04.593560Z"
    },
    "papermill": {
     "duration": 3.639975,
     "end_time": "2023-04-16T07:05:04.597592",
     "exception": false,
     "start_time": "2023-04-16T07:05:00.957617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for data wrangling\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import distinctipy\n",
    "from collections import defaultdict\n",
    "\n",
    "import random\n",
    "from torch_geometric.utils import from_networkx\n",
    "import shapely\n",
    "# from shapely import Point, MultiPolygon, GeometryCollection, Polygon, ops, LineString, unary_union, intersection_all\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon, Point, LineString, box\n",
    "from shapely.wkt import loads\n",
    "import geopandas as gpd\n",
    "# to show advance in for loops\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d633d942",
   "metadata": {
    "papermill": {
     "duration": 0.007436,
     "end_time": "2023-04-16T07:05:04.613865",
     "exception": false,
     "start_time": "2023-04-16T07:05:04.606429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='func'></a>\n",
    "### Functions used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "7190ba39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-16T07:05:04.630445Z",
     "iopub.status.busy": "2023-04-16T07:05:04.629728Z",
     "iopub.status.idle": "2023-04-16T07:05:04.854728Z",
     "shell.execute_reply": "2023-04-16T07:05:04.853571Z"
    },
    "papermill": {
     "duration": 0.236698,
     "end_time": "2023-04-16T07:05:04.857751",
     "exception": false,
     "start_time": "2023-04-16T07:05:04.621053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "room_embeddings = {\n",
    "    'living': 0,\n",
    "    'room': 1,\n",
    "    'kitchen': 2,\n",
    "    'bathroom': 3,\n",
    "    'balcony': 4\n",
    "}\n",
    "\n",
    "\n",
    "poly_types = list(room_embeddings.keys())\n",
    "N = len(poly_types)\n",
    "colors = (np.array(distinctipy.get_colors(N)) * 255).astype(np.uint8)\n",
    "room_color = {room_name: colors[i] for i, room_name in enumerate(poly_types)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "8232bbab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-16T07:05:04.874553Z",
     "iopub.status.busy": "2023-04-16T07:05:04.874164Z",
     "iopub.status.idle": "2023-04-16T07:05:04.883352Z",
     "shell.execute_reply": "2023-04-16T07:05:04.882308Z"
    },
    "papermill": {
     "duration": 0.019976,
     "end_time": "2023-04-16T07:05:04.885693",
     "exception": false,
     "start_time": "2023-04-16T07:05:04.865717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Handling_dubplicated_nodes(boundary, door):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is used to handle the duplicated nodes in the boundary graph.\n",
    "    As some coords of the boundary graph are near to each other, so we will consider them the same node.\n",
    "    \n",
    "    Input:\n",
    "        boundary graph, front door as polygons\n",
    "    Output:\n",
    "        boundary graph with no duplicated nodes. Also with the front door embedded.\n",
    "    \"\"\"\n",
    "    \n",
    "    coords = boundary.exterior.coords[:]\n",
    "        \n",
    "    # creating points:\n",
    "    points = []\n",
    "    for p in coords:\n",
    "        points.append(Point(p))\n",
    "\n",
    "    graph = nx.Graph()\n",
    "    # type of the node: 0 for boundary, 1 for front_door\n",
    "    graph.add_node(0, type=0, centroid=coords[0])\n",
    "\n",
    "    # to save the index if there is a node will not be added\n",
    "    current = 0\n",
    "    name = 1\n",
    "\n",
    "    for i in range(1, len(coords)):\n",
    "        dis = points[i].distance(points[current])\n",
    "        if dis >= 5:\n",
    "            # type of the node, edge = 0, front_door = 1\n",
    "            graph.add_node(name, type=0, centroid=coords[i])\n",
    "            current = i\n",
    "            name += 1\n",
    "\n",
    "    # Checking the distance between first and last node [if the distance is small, so we will consider them the same point]\n",
    "    nodes_names = list(graph.nodes)\n",
    "    first_node = Point(graph.nodes[nodes_names[0]]['centroid'])\n",
    "    last_node  = Point(graph.nodes[nodes_names[-1]]['centroid'])\n",
    "    if first_node.distance(last_node) <= 5:\n",
    "        graph.remove_node(nodes_names[-1])\n",
    "        nodes_names = list(graph.nodes)\n",
    "        \n",
    "    points_of_current_graph = []\n",
    "    for node in graph:\n",
    "        points_of_current_graph.append(Point(graph.nodes[node]['centroid']))\n",
    "\n",
    "    # Adding edges between nodes.\n",
    "    for i in range(len(nodes_names)-1):\n",
    "        dis = points_of_current_graph[i].distance(points_of_current_graph[i+1])\n",
    "        graph.add_edge(nodes_names[i],nodes_names[i+1], distance=dis)\n",
    "\n",
    "    # Adding an edge between the last and the first nodes.\n",
    "    dis = points_of_current_graph[nodes_names[0]].distance(points_of_current_graph[nodes_names[-1]])\n",
    "\n",
    "    graph.add_edge(nodes_names[0], nodes_names[-1], distance=dis)\n",
    "    \n",
    "    # adding the front door\n",
    "    graph = adding_door(graph, door, points_of_current_graph)\n",
    "    \n",
    "    return graph\n",
    "\n",
    "def adding_door(boundary_graph, door, points):\n",
    "    \"\"\"\n",
    "    This function is used to add the front door to the boundary graph.\n",
    "    Input:\n",
    "        boundary graph: graph of the boundary of the floor plan.\n",
    "        door: front door as polygon.\n",
    "        points: list of the points of the boundary graph. to use it to detect best place for the door.\n",
    "    \"\"\"\n",
    "    nearest_edge = None\n",
    "    nearest_dist = float('inf')\n",
    "    \n",
    "    dx = door.bounds[2] - door.bounds[0]\n",
    "    dy = door.bounds[3] - door.bounds[1]\n",
    "    door_oriantation_horizontal = dx > dy\n",
    "\n",
    "    for edge in boundary_graph.edges():\n",
    "        p1 = points[edge[0]]\n",
    "        p2 = points[edge[1]]\n",
    "\n",
    "        line = LineString([p1, p2])\n",
    "\n",
    "        # checking the oriantation of the lines.\n",
    "        p1x, p1y = p1.x, p1.y\n",
    "        p2x, p2y = p2.x, p2.y\n",
    "        dx = abs(p2x - p1x)\n",
    "        dy = abs(p2y - p1y)\n",
    "        line_oriantation_horizontal = dx > dy\n",
    "        \n",
    "        # print(f'edge: {edge}, line is: {line_oriantation_horizontal}, door is: {door_oriantation_horizontal}')\n",
    "        if door_oriantation_horizontal == line_oriantation_horizontal:\n",
    "            # getting nearest - with same oriantation - edge\n",
    "            dist = door.distance(line)\n",
    "            if dist < nearest_dist:\n",
    "                nearest_dist = dist\n",
    "                nearest_edge = edge\n",
    "\n",
    "    # print(f'nearest is: {nearest_edge}')\n",
    "    boundary_graph.remove_edge(*nearest_edge)\n",
    "    \n",
    "    door_ind = len(boundary_graph)\n",
    "    door_centroid = door.centroid\n",
    "    boundary_graph.add_node(door_ind, type=1, centroid=(door_centroid.x, door_centroid.y))\n",
    "\n",
    "    dist = door_centroid.distance(Point(boundary_graph.nodes[nearest_edge[0]]['centroid']))\n",
    "    boundary_graph.add_edge(nearest_edge[0], door_ind, distance=dist)\n",
    "\n",
    "    dist = door_centroid.distance(Point(boundary_graph.nodes[nearest_edge[1]]['centroid']))\n",
    "    boundary_graph.add_edge(nearest_edge[1], door_ind, distance=dist)\n",
    "    \n",
    "    return boundary_graph\n",
    "\n",
    "def centroids_to_graph(floor_plan, living_to_all=False, all_conected=False):\n",
    "    \"\"\"\n",
    "    Generating a graph for a specific floor plan\n",
    "    \n",
    "    Input: \n",
    "        floor_plan: a dictionary [key: type of room, value: list of centroids]\n",
    "        living_to_all: boolean, if True, we will connect all rooms to the living room.\n",
    "        all_conected: boolean, if True, we will connect all rooms to each other.\n",
    "    \n",
    "    Output:\n",
    "        G: a networkx graph represents the floor plan.\n",
    "    \"\"\"\n",
    "    # Creating new graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Embeding each room in a node.\n",
    "    for type_, list_of_centroids in floor_plan.items():\n",
    "        for i, centroid in enumerate(list_of_centroids):\n",
    "\n",
    "            currentNodeName = f'{type_}_{i}'\n",
    "            G.add_node(currentNodeName,\n",
    "                roomType_name = type_,\n",
    "                roomType_embd = room_embeddings[type_],\n",
    "                actualCentroid_x = centroid[0],\n",
    "                actualCentroid_y = centroid[1])\n",
    "            \n",
    "                                        \n",
    "    # if we need to connect all nodes to the living                    \n",
    "    if living_to_all: \n",
    "        living_cen = Point(G.nodes['living_0']['actualCentroid_x'], G.nodes['living_0']['actualCentroid_y'])\n",
    "        for node in G.nodes():\n",
    "                if G.nodes[node]['roomType_name'] != 'living':\n",
    "                    point = Point(G.nodes[node]['actualCentroid_x'], G.nodes[node]['actualCentroid_y'])\n",
    "                    dis = living_cen.distance(point)\n",
    "                    # adding edges between the living and all geoms\n",
    "                    G.add_edge('living_0', node, distance=round(dis, 3))\n",
    "                    \n",
    "    # if we need to connect all nodes to each others  \n",
    "    if all_conected: \n",
    "        for node in G.nodes():\n",
    "            current_node_centeroid = Point(G.nodes[node]['actualCentroid_x'], G.nodes[node]['actualCentroid_y'])\n",
    "\n",
    "            for other_node in G.nodes():\n",
    "                if other_node != node: # for all other rooms\n",
    "                    other_node_centeroid = Point(G.nodes[other_node]['actualCentroid_x'], G.nodes[other_node]['actualCentroid_y'])\n",
    "\n",
    "                    dis = current_node_centeroid.distance(other_node_centeroid)\n",
    "                    # adding edges between the the current node and the other nodes\n",
    "                    G.add_edge(node, other_node, distance=round(dis, 3))\n",
    "\n",
    "    return G\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def draw_graph(G):\n",
    "    \"\"\"\n",
    "    This function is used to draw the graph of rooms and user constrains.\n",
    "    \"\"\"\n",
    "    #  nodes positions for drawing, note that we invert the y pos\n",
    "    pos = {node: (G.nodes[node]['actualCentroid_x'], -G.nodes[node]['actualCentroid_y']) for node in G.nodes}\n",
    "    \n",
    "    colormap = [room_color[G.nodes[node]['roomType_name']]/255 for node in G]\n",
    "    \n",
    "    nx.draw(G, pos=pos, node_color=colormap, with_labels=True, font_size=12)\n",
    "\n",
    "\n",
    "def draw_graph_boundary(G):\n",
    "    \"\"\"\n",
    "    This function is used to draw the graph of the boundary of the floor plan.\n",
    "    \"\"\"\n",
    "    \n",
    "    #  nodes positions for drawing, note that we invert the y pos\n",
    "    pos = {node: (G.nodes[node]['centroid'][0], -G.nodes[node]['centroid'][1])  for node in G.nodes}\n",
    "    \n",
    "    door_color = '#90EE90'\n",
    "    other_nodes_color = '#0A2A5B'\n",
    "    color_map = [door_color if G.nodes[node]['type'] == 1 else other_nodes_color for node in G.nodes]\n",
    "    \n",
    "    nx.draw(G, pos=pos, with_labels=True, node_color=color_map, font_color='w', font_size=12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "086bffe5",
   "metadata": {
    "papermill": {
     "duration": 0.006753,
     "end_time": "2023-04-16T07:05:04.899507",
     "exception": false,
     "start_time": "2023-04-16T07:05:04.892754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='wrangling'></a>\n",
    "## Data wrangling\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4591b6d3",
   "metadata": {},
   "source": [
    "### User data / constrains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "8ce4cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(x):\n",
    "    if isinstance(x, tuple):\n",
    "        x = Point(*x)\n",
    "        \n",
    "    return aff.scale(x, xfact=1, yfact=-1, origin=(128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "e373e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data of the boundary of the floor plan\n",
    "boundary_wkt = \"POLYGON ((80.7357319426007 77.84654847012683, 157.16003903574074 77.84654847012683, 157.16003903574074 87.39958685676936, 230.4 87.39958685676936, 230.4 178.15345152987317, 28.194020816066946 178.15345152987317, 28.194020816066946 130.38825959666062, 80.7357319426007 130.38825959666062, 80.7357319426007 77.84654847012683))\"\n",
    "front_door_wkt = \"POLYGON ((25.599999999999948 133.94369064624638, 25.599999999999948 154.6958571747822, 28.194020816066946 154.6958571747822, 28.194020816066946 133.94369064624638, 25.599999999999948 133.94369064624638))\"\n",
    "# Data of the inner rooms or bathrooms\n",
    "room_centroids  = [(192, 119), (120, 106)]\n",
    "bathroom_centroids = [(208, 163), (91, 100)]\n",
    "\n",
    "room_centroids = [scale(x) for x in room_centroids]\n",
    "bathroom_centroids = [scale(x) for x in bathroom_centroids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "2dc0c21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"221.18400000000008\" height=\"116.69090305974635\" viewBox=\"17.407999999999944 69.65454847012683 221.18400000000008 116.69090305974635\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,256.0)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"2.0\" opacity=\"0.6\" d=\"M 157.16003903574074,178.15345152987317 L 157.16003903574074,168.60041314323064 L 230.4,168.60041314323064 L 230.4,77.84654847012683 L 28.194020816066946,77.84654847012683 L 28.194020816066946,101.30414282521781 L 25.599999999999948,101.30414282521781 L 25.599999999999948,122.05630935375362 L 28.194020816066946,122.05630935375362 L 28.194020816066946,125.61174040333938 L 80.7357319426007,125.61174040333938 L 80.7357319426007,178.15345152987317 L 157.16003903574074,178.15345152987317 z\" /></g></svg>"
      ],
      "text/plain": [
       "<POLYGON ((157.16 178.153, 157.16 168.6, 230.4 168.6, 230.4 77.847, 28.194 7...>"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the boundary & front door as shapely polygons\n",
    "boundary = shapely.wkt.loads(boundary_wkt)\n",
    "front_door = shapely.wkt.loads(front_door_wkt)\n",
    "\n",
    "# plotting the boundary as polygon.\n",
    "import shapely.affinity as aff\n",
    "\n",
    "boundary   = scale(boundary)\n",
    "front_door = scale(front_door)\n",
    "\n",
    "boundary | front_door"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "2ff5c47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "room_centroids = [x.coords[0] for x in room_centroids]\n",
    "bathroom_centroids = [x.coords[0] for x in bathroom_centroids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "1c87975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_graph = Handling_dubplicated_nodes(boundary, front_door)\n",
    "# draw_graph_boundary(boundary_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "b3d41c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering the center of the living room as the origin of the floor plan\n",
    "living_centroid    = [(boundary.centroid.x, boundary.centroid.y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "0da98e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_constraints = {\n",
    "    'living': living_centroid,\n",
    "    'room': room_centroids,\n",
    "    'bathroom': bathroom_centroids\n",
    "}\n",
    "\n",
    "G = centroids_to_graph(user_constraints, all_conected=True)\n",
    "# draw_graph(G)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29f3ef39",
   "metadata": {
    "papermill": {
     "duration": 0.05316,
     "end_time": "2023-04-16T07:06:28.314088",
     "exception": false,
     "start_time": "2023-04-16T07:06:28.260928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='archi'></a>\n",
    "### Architecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f23c802",
   "metadata": {},
   "source": [
    "> Converting graphs to pytorch geometric graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "74758c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boundary graph\n",
    "B_pytorch = from_networkx(boundary_graph, group_node_attrs=['type', 'centroid'], group_edge_attrs=['distance'])\n",
    "\n",
    "# Floor plan graph\n",
    "features = ['roomType_embd', 'actualCentroid_x', 'actualCentroid_y']\n",
    "G_pytorch = from_networkx(G, group_edge_attrs=['distance'], group_node_attrs=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "b45a74cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000, 138.8954, 122.1935],\n",
       "        [  1.0000, 192.0000, 137.0000],\n",
       "        [  1.0000, 120.0000, 150.0000],\n",
       "        [  3.0000, 208.0000,  93.0000],\n",
       "        [  3.0000,  91.0000, 156.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_pytorch.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "7bc7df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_x = G_pytorch.x[:, 1].mean().item()\n",
    "mean_y = G_pytorch.x[:, 2].mean().item()\n",
    "\n",
    "std_x = G_pytorch.x[:, 1].std().item()\n",
    "std_y = G_pytorch.x[:, 2].std().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "f2538e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2259,\n",
       "         -0.3747],\n",
       "        [ 0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.8563,\n",
       "          0.2127],\n",
       "        [ 0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.6109,\n",
       "          0.7284],\n",
       "        [ 0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.1824,\n",
       "         -1.5329],\n",
       "        [ 0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000, -1.2019,\n",
       "          0.9665]], dtype=torch.float64)"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "for i in [1, 2]:\n",
    "    if i == 1:\n",
    "        G_pytorch.x[:, i] = (G_pytorch.x[:, i] - mean_x) / std_x\n",
    "    elif i == 2:\n",
    "        G_pytorch.x[:, i] = (G_pytorch.x[:, i] - mean_y) / std_y\n",
    "        \n",
    "first_column_encodings = F.one_hot(G_pytorch.x[:, 0].long(), num_classes=7).to(torch.float)\n",
    "G_pytorch.x = torch.cat([first_column_encodings, G_pytorch.x[:, 1:]], dim=1)\n",
    "\n",
    "G_pytorch.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac4aafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "8601daf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_bou_x = B_pytorch.x[:, 1].mean().item()\n",
    "mean_bou_y = B_pytorch.x[:, 2].mean().item()\n",
    "\n",
    "std_bou_x = B_pytorch.x[:, 1].std().item()\n",
    "std_bou_y = B_pytorch.x[:, 2].std().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "c18e1cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -0.3918,  1.0689],\n",
       "        [ 0.0000,  0.5271,  1.0689],\n",
       "        [ 0.0000,  0.5271,  0.8340],\n",
       "        [ 0.0000,  1.4076,  0.8340],\n",
       "        [ 0.0000,  1.4076, -1.3973],\n",
       "        [ 0.0000, -1.0235, -1.3973],\n",
       "        [ 0.0000, -1.0235, -0.2229],\n",
       "        [ 0.0000, -0.3918, -0.2229],\n",
       "        [ 1.0000, -1.0390, -0.5654]], dtype=torch.float64)"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "for i in [1, 2]:\n",
    "    if i == 1:\n",
    "        B_pytorch.x[:, i] = (B_pytorch.x[:, i] - mean_bou_x) / std_bou_x\n",
    "    elif i == 2:\n",
    "        B_pytorch.x[:, i] = (B_pytorch.x[:, i] - mean_bou_y) / std_bou_y\n",
    "        \n",
    "B_pytorch.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "58a7a8dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-16T07:06:28.421500Z",
     "iopub.status.busy": "2023-04-16T07:06:28.419439Z",
     "iopub.status.idle": "2023-04-16T07:06:31.330478Z",
     "shell.execute_reply": "2023-04-16T07:06:31.329316Z"
    },
    "papermill": {
     "duration": 2.96638,
     "end_time": "2023-04-16T07:06:31.332938",
     "exception": false,
     "start_time": "2023-04-16T07:06:28.366558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GATNet(\n",
       "  (graph_conv1): GATConv(9, 32, heads=4)\n",
       "  (graph_conv2): GATConv(137, 32, heads=8)\n",
       "  (graph_conv3): GATConv(265, 64, heads=8)\n",
       "  (graph_conv4): GATConv(521, 128, heads=8)\n",
       "  (boundary_conv1): GATConv(3, 32, heads=4)\n",
       "  (boundary_conv2): GATConv(131, 32, heads=8)\n",
       "  (Concatination1): GATConv(1292, 128, heads=8)\n",
       "  (width_layer1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (height_layer1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (width_output): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (height_output): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (boundary_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch.utils.data import Dataset\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "\n",
    "# For the GNN model\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv, global_mean_pool, global_max_pool\n",
    "\n",
    "\n",
    "class GATNet(torch.nn.Module):\n",
    "    def __init__(self, num_graph_node_features, num_boundary_node_features):\n",
    "        super(GATNet, self).__init__()\n",
    "        \n",
    "        self.graph_conv1 = GATConv(num_graph_node_features, 32, heads=4)\n",
    "        \n",
    "        input_of_conv2   = num_graph_node_features + 32*4\n",
    "        self.graph_conv2 = GATConv(input_of_conv2, 32, heads=8)\n",
    "        \n",
    "        input_of_conv3   = num_graph_node_features + 32*8\n",
    "        self.graph_conv3 = GATConv(input_of_conv3, 64, heads=8)\n",
    "        \n",
    "        input_of_conv4   = num_graph_node_features + 64*8\n",
    "        self.graph_conv4 = GATConv(input_of_conv4, 128, heads=8)\n",
    "        shape_of_graphs_befor_concatination = num_graph_node_features + 128*8\n",
    "        \n",
    "        self.boundary_conv1 = GATConv(num_boundary_node_features, 32, heads=4)\n",
    "        input_of_boundary_conv2 = 32*4 + num_boundary_node_features\n",
    "        self.boundary_conv2 = GATConv(input_of_boundary_conv2, 32, heads=8)\n",
    "        \n",
    "        shape_of_boundary_befor_concatination = num_boundary_node_features + 32 * 8\n",
    "        \n",
    "        # Output of graph_conv8 + output of boundary_conv5 + 2 step connection from real nodes and boundary nodes\n",
    "        inputs_concatination = shape_of_graphs_befor_concatination + shape_of_boundary_befor_concatination\n",
    "        self.Concatination1  = GATConv(inputs_concatination, 128, heads=8)\n",
    "\n",
    "        self.width_layer1  = nn.Linear(128*8, 128)\n",
    "        self.height_layer1 = nn.Linear(128*8, 128)\n",
    "        \n",
    "        self.width_output  = nn.Linear(128, 1)\n",
    "        self.height_output = nn.Linear(128, 1)\n",
    "        \n",
    "        \n",
    "        self.boundary_pool = torch.nn.AdaptiveAvgPool1d(1)\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, graph, boundary):\n",
    "        x_graph, g_edge_index, g_edge_attr, g_batch = graph.x, graph.edge_index, graph.edge_attr, graph.batch\n",
    "        x_boundary, b_edge_indexy, b_edge_attr, b_batch = boundary.x, boundary.edge_index, boundary.edge_attr, boundary.batch\n",
    "        \n",
    "        NUM_OF_NODES = x_graph.shape[0]\n",
    "        # During testing, as we input only one graph.\n",
    "        if g_batch == None:\n",
    "            g_batch = torch.zeros(x_graph.shape[0], dtype=torch.long)\n",
    "        if b_batch == None:\n",
    "            b_batch = torch.zeros(x_boundary.shape[0], dtype=torch.long)\n",
    "        \n",
    "        \n",
    "        x_graph_res = x_graph\n",
    "        x_boundary_res = x_boundary\n",
    "        \n",
    "        # Passing the graph throught a message passing to embed its features\n",
    "        x_graph = F.leaky_relu(self.graph_conv1(x_graph, g_edge_index, g_edge_attr))\n",
    "        x_graph = self.dropout(x_graph) # Concatinate with step connection from real values.\n",
    "        x_graph = torch.cat([x_graph, x_graph_res], dim=1)\n",
    "        \n",
    "        \n",
    "        x_graph = F.leaky_relu(self.graph_conv2(x_graph, g_edge_index, g_edge_attr))\n",
    "        x_graph = self.dropout(x_graph)\n",
    "        x_graph = torch.cat([x_graph, x_graph_res], dim=1)\n",
    "        \n",
    "        x_graph = F.leaky_relu(self.graph_conv3(x_graph, g_edge_index))\n",
    "        x_graph = self.dropout(x_graph) \n",
    "        x_graph = torch.cat([x_graph, x_graph_res], dim=1)\n",
    "        \n",
    "        x_graph = F.leaky_relu(self.graph_conv4(x_graph, g_edge_index))\n",
    "        x_graph = self.dropout(x_graph) \n",
    "        x_graph = torch.cat([x_graph, x_graph_res], dim=1)\n",
    "        \n",
    "        # Passing the boundary throught a message passing to embed its features\n",
    "        x_boundary = F.leaky_relu(self.boundary_conv1(x_boundary, b_edge_indexy, b_edge_attr))\n",
    "        x_boundary = self.dropout(x_boundary)\n",
    "        x_boundary = torch.cat([x_boundary, x_boundary_res], dim=1)\n",
    "        \n",
    "        x_boundary = F.leaky_relu(self.boundary_conv2(x_boundary, b_edge_indexy, b_edge_attr))\n",
    "        x_boundary = self.dropout(x_boundary)\n",
    "        x_boundary = torch.cat([x_boundary, x_boundary_res], dim=1)\n",
    "\n",
    "        # Pooling the bounadry to 1D vector by getting max value in each feature for all nodes.\n",
    "        x_boundary_pooled = F.max_pool1d(x_boundary.transpose(0, 1), kernel_size=x_boundary.shape[0]).view(1, -1)\n",
    "        \n",
    "        # Concatinating the graph & the boundary\n",
    "        x = torch.cat([x_graph, x_boundary_pooled.repeat(NUM_OF_NODES, 1)], dim=1)\n",
    "        x = F.leaky_relu(self.Concatination1(x, g_edge_index))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        \n",
    "        width = F.leaky_relu(self.width_layer1(x))\n",
    "        width = self.dropout(width)\n",
    "        width = self.width_output(width)\n",
    "        \n",
    "        height = F.leaky_relu(self.height_layer1(x))\n",
    "        height = self.dropout(height)\n",
    "        height = self.height_output(height)\n",
    "        \n",
    "        return width.squeeze(), height.squeeze()\n",
    "\n",
    "num_graph_node_features = G_pytorch.x.shape[1]\n",
    "num_boundary_node_features = B_pytorch.x.shape[1]\n",
    "\n",
    "model = GATNet(num_graph_node_features, num_boundary_node_features)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# to monitor the loss & accuracy.\n",
    "errors = []\n",
    "acc = []\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "ffd9a9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GATNet(\n",
       "  (graph_conv1): GATConv(9, 32, heads=4)\n",
       "  (graph_conv2): GATConv(137, 32, heads=8)\n",
       "  (graph_conv3): GATConv(265, 64, heads=8)\n",
       "  (graph_conv4): GATConv(521, 128, heads=8)\n",
       "  (boundary_conv1): GATConv(3, 32, heads=4)\n",
       "  (boundary_conv2): GATConv(131, 32, heads=8)\n",
       "  (Concatination1): GATConv(1292, 128, heads=8)\n",
       "  (width_layer1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (height_layer1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (width_output): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (height_output): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (boundary_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = r\"Regressions\\squares_w_h\\checkpoints\\v2\\Best_model_V2.pt\"\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "optimizer.param_groups[0]['params'][0].data.float()\n",
    "epochs = checkpoint['epoch']\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "4430946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FloorPlan_multipolygon():\n",
    "    def __init__(self, graph, prediction):\n",
    "        self.graph       = graph\n",
    "        self.prediction  = prediction\n",
    "        \n",
    "    def get_room_data(self, room_index):\n",
    "        \"\"\"\n",
    "        Inputs: \n",
    "            room_index: index of the room in the graph\n",
    "            \n",
    "        Outputs: \n",
    "            centroid, w, h of that room.\n",
    "        \"\"\"\n",
    "        # # Using networkX graphs\n",
    "        # Graph_data = list(self.graph.nodes(data=True))[room_index][1]\n",
    "        # w = Graph_data['rec_w']\n",
    "        # h = Graph_data['rec_h']\n",
    "        # centroid = (Graph_data['actualCentroid_x'], Graph_data['actualCentroid_y'])\n",
    "        # category = Graph_data['roomType_embd']\n",
    "        \n",
    "        # Using pytorhc Garphs\n",
    "        \n",
    "        centroid = (self.graph.x[room_index][-2].item(), self.graph.x[room_index][-1].item())\n",
    "        category = torch.argmax(G_pytorch.x[:, :7], axis=1)[room_index].item()\n",
    "        w_pre, h_pre = self.get_predictions(room_index)\n",
    "            \n",
    "\n",
    "        data = {\n",
    "            'centroid': centroid,\n",
    "            'predic_w': w_pre,\n",
    "            'predic_h': h_pre,\n",
    "            'category': category\n",
    "        }\n",
    "        return data\n",
    "    \n",
    "    def create_box(self, room_data):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            room_data: a dictionary with centroid, w, h of that room.\n",
    "            \n",
    "        Outputs:\n",
    "            box: a shapely box with the same centroid, w, h of that room.\n",
    "        \"\"\"\n",
    "        \n",
    "        centroid = room_data['centroid']\n",
    "        half_w   = room_data['predic_w'] / 2\n",
    "        half_h   = room_data['predic_h'] / 2\n",
    "        \n",
    "        # bottom_left  = Point(centroid[0] - half_w, centroid[1] - half_h)\n",
    "        # bottom_right = Point(centroid[0] + half_w, centroid[1] - half_h)\n",
    "        # top_right    = Point(centroid[0] + half_w, centroid[1] + half_h)\n",
    "        # top_left     = Point(centroid[0] - half_w, centroid[1] + half_h)\n",
    "        \n",
    "        x1 = centroid[0] - half_w\n",
    "        x2 = centroid[0] + half_w\n",
    "        y1 = centroid[1] - half_h\n",
    "        y2 = centroid[1] + half_h\n",
    "        \n",
    "        # print(bottom_left, bottom_right, top_right, top_left)\n",
    "        # box = Polygon([bottom_left, bottom_right, top_right, top_left])\n",
    "        box_poly = box(x1, y1, x2, y2)\n",
    "        return box_poly\n",
    "\n",
    "    def get_multipoly(self, boundary=False):\n",
    "        \"\"\"\n",
    "        Outputs:\n",
    "            multi_poly: a shapely multipolygon of all the rooms in the floor plan or graph.\n",
    "        \"\"\"\n",
    "        num_of_rooms = self.graph.x.shape[0]\n",
    "        similar_polygons = defaultdict(list)\n",
    "        \n",
    "        for index in range(num_of_rooms):\n",
    "            room_data = self.get_room_data(index)\n",
    "            box = self.create_box(room_data)\n",
    "            \n",
    "            # add each pox to its similar boxes\n",
    "            room_category = room_data['category']\n",
    "            if room_category != 0:\n",
    "                similar_polygons[room_category].append(box)\n",
    "\n",
    "        \n",
    "        all_polygons = []\n",
    "        all_polygons.append(boundary)\n",
    "        for _, polygons in similar_polygons.items():\n",
    "            all_polygons.append(MultiPolygon(polygons))\n",
    "        \n",
    "        # all_polygons.append(boundary)\n",
    "        compined_polygons_seperated = gpd.GeoSeries(all_polygons)\n",
    "        \n",
    "        return compined_polygons_seperated\n",
    "    \n",
    "    def get_predictions(self, room_index):\n",
    "        \"\"\"\n",
    "        Inputs: \n",
    "            room_index: index of the room in the graph\n",
    "        outputs: \n",
    "            w_predicted: predicted width for that room\n",
    "            h_predicted: predicted width for that room\n",
    "        \"\"\"\n",
    "        w_predicted = self.prediction[room_index, 0]\n",
    "        h_predicted = self.prediction[room_index, 1]\n",
    "        \n",
    "        return w_predicted, h_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "c1098ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_pytorch.x = G_pytorch.x.to(torch.float32)\n",
    "G_pytorch.edge_attr = G_pytorch.edge_attr.to(torch.float32)\n",
    "G_pytorch.edge_index = G_pytorch.edge_index.to(torch.int64)\n",
    "\n",
    "B_pytorch.x = B_pytorch.x.to(G_pytorch.x.dtype)\n",
    "B_pytorch.edge_index = B_pytorch.edge_index.to(G_pytorch.edge_index.dtype)\n",
    "B_edge_attr = B_pytorch.edge_attr.to(G_pytorch.edge_attr.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "3d83e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(G_pytorch.to(device), B_pytorch.to(device))\n",
    "\n",
    "w_predicted   = prediction[0].detach().cpu().numpy()\n",
    "h_predicted   = prediction[1].detach().cpu().numpy()\n",
    "prediction = np.concatenate([w_predicted.reshape(-1, 1), h_predicted.reshape(-1, 1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "709dd26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get back real values of centroids to use them In the visualization\n",
    "G_pytorch.x[:, -2] = G_pytorch.x[:, -2] * std_x + mean_x\n",
    "G_pytorch.x[:, -1] = G_pytorch.x[:, -1] * std_y + mean_y\n",
    "\n",
    "B_pytorch.x[:, -2] = B_pytorch.x[:, -2] * std_bou_x + mean_bou_x\n",
    "B_pytorch.x[:, -1] = B_pytorch.x[:, -1] * std_bou_y + mean_bou_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "d54aae74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# w_h_predicted = model(G.to(device), B.to(device)).detach().cpu().numpy()\n",
    "test = FloorPlan_multipolygon(G_pytorch, prediction=prediction)\n",
    "\n",
    "polys = test.get_multipoly(boundary)\n",
    "polys.plot(cmap='Dark2_r', figsize=(4, 4), alpha=0.5, linewidth=0.5, edgecolor='black');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f12e45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17190.24346,
   "end_time": "2023-04-16T11:50:47.981067",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-16T07:04:17.737607",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
