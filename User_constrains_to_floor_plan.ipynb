{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7edfe0a6",
   "metadata": {
    "papermill": {
     "duration": 0.008886,
     "end_time": "2023-04-16T07:04:27.220632",
     "exception": false,
     "start_time": "2023-04-16T07:04:27.211746",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Planify - User constrains to floor plan\n",
    "\n",
    "### Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#intro\">Introduction</a></li>\n",
    "    <ul>\n",
    "        <li><a href=\"#Imports\">Imports</a></li>\n",
    "        <li><a href=\"#func\">Functions used</a></li>\n",
    "    </ul>\n",
    "<li><a href=\"#wrangling\">Data Wrangling</a></li>\n",
    "<li><a href=\"#model\">GNN Model</a></li>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c40f6938",
   "metadata": {
    "papermill": {
     "duration": 0.007171,
     "end_time": "2023-04-16T07:04:27.235516",
     "exception": false,
     "start_time": "2023-04-16T07:04:27.228345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "> This notebook getting garphs in the Networkx format from the `Creating Graphs` notebook. And its main goal is to make the GNN model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0700caf5",
   "metadata": {
    "papermill": {
     "duration": 0.007268,
     "end_time": "2023-04-16T07:04:27.276656",
     "exception": false,
     "start_time": "2023-04-16T07:04:27.269388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='Imports'></a>\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdec8865",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-16T07:05:00.966534Z",
     "iopub.status.busy": "2023-04-16T07:05:00.966170Z",
     "iopub.status.idle": "2023-04-16T07:05:04.594842Z",
     "shell.execute_reply": "2023-04-16T07:05:04.593560Z"
    },
    "papermill": {
     "duration": 3.639975,
     "end_time": "2023-04-16T07:05:04.597592",
     "exception": false,
     "start_time": "2023-04-16T07:05:00.957617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for data wrangling\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import distinctipy\n",
    "import random\n",
    "from torch_geometric.utils import from_networkx\n",
    "import shapely\n",
    "from shapely import Point, MultiPolygon, GeometryCollection, Polygon, ops, LineString, unary_union, intersection_all\n",
    "from shapely.wkt import loads\n",
    "# to show advance in for loops\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d633d942",
   "metadata": {
    "papermill": {
     "duration": 0.007436,
     "end_time": "2023-04-16T07:05:04.613865",
     "exception": false,
     "start_time": "2023-04-16T07:05:04.606429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='func'></a>\n",
    "### Functions used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7190ba39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-16T07:05:04.630445Z",
     "iopub.status.busy": "2023-04-16T07:05:04.629728Z",
     "iopub.status.idle": "2023-04-16T07:05:04.854728Z",
     "shell.execute_reply": "2023-04-16T07:05:04.853571Z"
    },
    "papermill": {
     "duration": 0.236698,
     "end_time": "2023-04-16T07:05:04.857751",
     "exception": false,
     "start_time": "2023-04-16T07:05:04.621053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "room_embeddings = {\n",
    "    'living': 0,\n",
    "    'room': 1,\n",
    "    'kitchen': 2,\n",
    "    'bathroom': 3,\n",
    "    'balcony': 4\n",
    "}\n",
    "\n",
    "\n",
    "poly_types = list(room_embeddings.keys())\n",
    "N = len(poly_types)\n",
    "colors = (np.array(distinctipy.get_colors(N)) * 255).astype(np.uint8)\n",
    "room_color = {room_name: colors[i] for i, room_name in enumerate(poly_types)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8232bbab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-16T07:05:04.874553Z",
     "iopub.status.busy": "2023-04-16T07:05:04.874164Z",
     "iopub.status.idle": "2023-04-16T07:05:04.883352Z",
     "shell.execute_reply": "2023-04-16T07:05:04.882308Z"
    },
    "papermill": {
     "duration": 0.019976,
     "end_time": "2023-04-16T07:05:04.885693",
     "exception": false,
     "start_time": "2023-04-16T07:05:04.865717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Handling_dubplicated_nodes(boundary, door):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is used to handle the duplicated nodes in the boundary graph.\n",
    "    As some coords of the boundary graph are near to each other, so we will consider them the same node.\n",
    "    \n",
    "    Input:\n",
    "        boundary graph, front door as polygons\n",
    "    Output:\n",
    "        boundary graph with no duplicated nodes. Also with the front door embedded.\n",
    "    \"\"\"\n",
    "    \n",
    "    coords = boundary.exterior.coords[:]\n",
    "        \n",
    "    # creating points:\n",
    "    points = []\n",
    "    for p in coords:\n",
    "        points.append(Point(p))\n",
    "\n",
    "    graph = nx.Graph()\n",
    "    # type of the node: 0 for boundary, 1 for front_door\n",
    "    graph.add_node(0, type=0, centroid=coords[0])\n",
    "\n",
    "    # to save the index if there is a node will not be added\n",
    "    current = 0\n",
    "    name = 1\n",
    "\n",
    "    for i in range(1, len(coords)):\n",
    "        dis = points[i].distance(points[current])\n",
    "        if dis >= 5:\n",
    "            # type of the node, edge = 0, front_door = 1\n",
    "            graph.add_node(name, type=0, centroid=coords[i])\n",
    "            current = i\n",
    "            name += 1\n",
    "\n",
    "    # Checking the distance between first and last node [if the distance is small, so we will consider them the same point]\n",
    "    nodes_names = list(graph.nodes)\n",
    "    first_node = Point(graph.nodes[nodes_names[0]]['centroid'])\n",
    "    last_node  = Point(graph.nodes[nodes_names[-1]]['centroid'])\n",
    "    if first_node.distance(last_node) <= 5:\n",
    "        graph.remove_node(nodes_names[-1])\n",
    "        nodes_names = list(graph.nodes)\n",
    "        \n",
    "    points_of_current_graph = []\n",
    "    for node in graph:\n",
    "        points_of_current_graph.append(Point(graph.nodes[node]['centroid']))\n",
    "\n",
    "    # Adding edges between nodes.\n",
    "    for i in range(len(nodes_names)-1):\n",
    "        dis = points_of_current_graph[i].distance(points_of_current_graph[i+1])\n",
    "        graph.add_edge(nodes_names[i],nodes_names[i+1], distance=dis)\n",
    "\n",
    "    # Adding an edge between the last and the first nodes.\n",
    "    dis = points_of_current_graph[nodes_names[0]].distance(points_of_current_graph[nodes_names[-1]])\n",
    "\n",
    "    graph.add_edge(nodes_names[0], nodes_names[-1], distance=dis)\n",
    "    \n",
    "    # adding the front door\n",
    "    graph = adding_door(graph, door, points_of_current_graph)\n",
    "    \n",
    "    return graph\n",
    "\n",
    "def adding_door(boundary_graph, door, points):\n",
    "    \"\"\"\n",
    "    This function is used to add the front door to the boundary graph.\n",
    "    Input:\n",
    "        boundary graph: graph of the boundary of the floor plan.\n",
    "        door: front door as polygon.\n",
    "        points: list of the points of the boundary graph. to use it to detect best place for the door.\n",
    "    \"\"\"\n",
    "    nearest_edge = None\n",
    "    nearest_dist = float('inf')\n",
    "    \n",
    "    dx = door.bounds[2] - door.bounds[0]\n",
    "    dy = door.bounds[3] - door.bounds[1]\n",
    "    door_oriantation_horizontal = dx > dy\n",
    "\n",
    "    for edge in boundary_graph.edges():\n",
    "        p1 = points[edge[0]]\n",
    "        p2 = points[edge[1]]\n",
    "\n",
    "        line = LineString([p1, p2])\n",
    "\n",
    "        # checking the oriantation of the lines.\n",
    "        p1x, p1y = p1.x, p1.y\n",
    "        p2x, p2y = p2.x, p2.y\n",
    "        dx = abs(p2x - p1x)\n",
    "        dy = abs(p2y - p1y)\n",
    "        line_oriantation_horizontal = dx > dy\n",
    "        \n",
    "        # print(f'edge: {edge}, line is: {line_oriantation_horizontal}, door is: {door_oriantation_horizontal}')\n",
    "        if door_oriantation_horizontal == line_oriantation_horizontal:\n",
    "            # getting nearest - with same oriantation - edge\n",
    "            dist = door.distance(line)\n",
    "            if dist < nearest_dist:\n",
    "                nearest_dist = dist\n",
    "                nearest_edge = edge\n",
    "\n",
    "    # print(f'nearest is: {nearest_edge}')\n",
    "    boundary_graph.remove_edge(*nearest_edge)\n",
    "    \n",
    "    door_ind = len(boundary_graph)\n",
    "    door_centroid = door.centroid\n",
    "    boundary_graph.add_node(door_ind, type=1, centroid=(door_centroid.x, door_centroid.y))\n",
    "\n",
    "    dist = door_centroid.distance(Point(boundary_graph.nodes[nearest_edge[0]]['centroid']))\n",
    "    boundary_graph.add_edge(nearest_edge[0], door_ind, distance=dist)\n",
    "\n",
    "    dist = door_centroid.distance(Point(boundary_graph.nodes[nearest_edge[1]]['centroid']))\n",
    "    boundary_graph.add_edge(nearest_edge[1], door_ind, distance=dist)\n",
    "    \n",
    "    return boundary_graph\n",
    "\n",
    "def centroids_to_graph(floor_plan, living_to_all=False, all_conected=False):\n",
    "    \"\"\"\n",
    "    Generating a graph for a specific floor plan\n",
    "    \n",
    "    Input: \n",
    "        floor_plan: a dictionary [key: type of room, value: list of centroids]\n",
    "        living_to_all: boolean, if True, we will connect all rooms to the living room.\n",
    "        all_conected: boolean, if True, we will connect all rooms to each other.\n",
    "    \n",
    "    Output:\n",
    "        G: a networkx graph represents the floor plan.\n",
    "    \"\"\"\n",
    "    # Creating new graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Embeding each room in a node.\n",
    "    for type_, list_of_centroids in floor_plan.items():\n",
    "        for i, centroid in enumerate(list_of_centroids):\n",
    "\n",
    "            currentNodeName = f'{type_}_{i}'\n",
    "            G.add_node(currentNodeName,\n",
    "                roomType_name = type_,\n",
    "                roomType_embd = room_embeddings[type_],\n",
    "                actualCentroid_x = centroid[0],\n",
    "                actualCentroid_y = centroid[1])\n",
    "            \n",
    "                                        \n",
    "    # if we need to connect all nodes to the living                    \n",
    "    if living_to_all: \n",
    "        living_cen = Point(G.nodes['living_0']['actualCentroid_x'], G.nodes['living_0']['actualCentroid_y'])\n",
    "        for node in G.nodes():\n",
    "                if G.nodes[node]['roomType_name'] != 'living':\n",
    "                    point = Point(G.nodes[node]['actualCentroid_x'], G.nodes[node]['actualCentroid_y'])\n",
    "                    dis = living_cen.distance(point)\n",
    "                    # adding edges between the living and all geoms\n",
    "                    G.add_edge('living_0', node, distance=round(dis, 3))\n",
    "                    \n",
    "    # if we need to connect all nodes to each others  \n",
    "    if all_conected: \n",
    "        for node in G.nodes():\n",
    "            current_node_centeroid = Point(G.nodes[node]['actualCentroid_x'], G.nodes[node]['actualCentroid_y'])\n",
    "\n",
    "            for other_node in G.nodes():\n",
    "                if other_node != node: # for all other rooms\n",
    "                    other_node_centeroid = Point(G.nodes[other_node]['actualCentroid_x'], G.nodes[other_node]['actualCentroid_y'])\n",
    "\n",
    "                    dis = current_node_centeroid.distance(other_node_centeroid)\n",
    "                    # adding edges between the the current node and the other nodes\n",
    "                    G.add_edge(node, other_node, distance=round(dis, 3))\n",
    "\n",
    "    return G\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def draw_graph(G):\n",
    "    \"\"\"\n",
    "    This function is used to draw the graph of rooms and user constrains.\n",
    "    \"\"\"\n",
    "    #  nodes positions for drawing, note that we invert the y pos\n",
    "    pos = {node: (G.nodes[node]['actualCentroid_x'], -G.nodes[node]['actualCentroid_y']) for node in G.nodes}\n",
    "    \n",
    "    colormap = [room_color[G.nodes[node]['roomType_name']]/255 for node in G]\n",
    "    \n",
    "    nx.draw(G, pos=pos, node_color=colormap, with_labels=True, font_size=12)\n",
    "\n",
    "\n",
    "def draw_graph_boundary(G):\n",
    "    \"\"\"\n",
    "    This function is used to draw the graph of the boundary of the floor plan.\n",
    "    \"\"\"\n",
    "    \n",
    "    #  nodes positions for drawing, note that we invert the y pos\n",
    "    pos = {node: (G.nodes[node]['centroid'][0], -G.nodes[node]['centroid'][1])  for node in G.nodes}\n",
    "    \n",
    "    door_color = '#90EE90'\n",
    "    other_nodes_color = '#0A2A5B'\n",
    "    color_map = [door_color if G.nodes[node]['type'] == 1 else other_nodes_color for node in G.nodes]\n",
    "    \n",
    "    nx.draw(G, pos=pos, with_labels=True, node_color=color_map, font_color='w', font_size=12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "086bffe5",
   "metadata": {
    "papermill": {
     "duration": 0.006753,
     "end_time": "2023-04-16T07:05:04.899507",
     "exception": false,
     "start_time": "2023-04-16T07:05:04.892754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='wrangling'></a>\n",
    "## Data wrangling\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4591b6d3",
   "metadata": {},
   "source": [
    "### User data / constrains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e373e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data of the boundary of the floor plan\n",
    "boundary_wkt   = 'POLYGON ((25.599999999999994 65.17869060128213, 53.527272727272745 65.17869060128213, 53.527272727272745 71.38475120734273, 135.7575757575758 71.38475120734273, 135.7575757575758 79.14232696491848, 230.4 79.14232696491848, 230.4 193.9544481770397, 25.599999999999994 193.9544481770397, 25.599999999999994 65.17869060128213))'\n",
    "front_door_wkt = \"POLYGON ((52.786267475558176 62.04555182296029, 27.721157248983484 62.04555182296029, 27.721157248983484 65.17869060128213, 52.786267475558176 65.17869060128213, 52.786267475558176 62.04555182296029))\"\n",
    "\n",
    "# Data of the inner rooms or bathrooms\n",
    "room_centroids  = [(192, 164), (190, 107), (60, 165)]\n",
    "bathroom_centroids = [(145, 98), (146, 172), (107, 175)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2dc0c21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"221.18400000000003\" height=\"145.15975757575757\" viewBox=\"17.407999999999994 56.98669060128213 221.18400000000003 145.15975757575757\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,259.13313877832184)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"2.0\" opacity=\"0.6\" d=\"M 25.599999999999994,65.17869060128213 L 53.527272727272745,65.17869060128213 L 53.527272727272745,71.38475120734273 L 135.7575757575758,71.38475120734273 L 135.7575757575758,79.14232696491848 L 230.4,79.14232696491848 L 230.4,193.9544481770397 L 25.599999999999994,193.9544481770397 L 25.599999999999994,65.17869060128213 z\" /></g></svg>"
      ],
      "text/plain": [
       "<POLYGON ((25.6 65.179, 53.527 65.179, 53.527 71.385, 135.758 71.385, 135.75...>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the boundary & front door as shapely polygons\n",
    "\n",
    "boundary = shapely.wkt.loads(boundary_wkt)\n",
    "front_door = shapely.wkt.loads(front_door_wkt)\n",
    "\n",
    "# plotting the boundary as polygon.\n",
    "boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1c87975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_graph = Handling_dubplicated_nodes(boundary, front_door)\n",
    "# draw_graph_boundary(boundary_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b3d41c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering the center of the living room as the origin of the floor plan\n",
    "living_centroid    = [(boundary.centroid.x, boundary.centroid.y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0da98e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_constraints = {\n",
    "    'living': living_centroid,\n",
    "    'room': room_centroids,\n",
    "    'bathroom': bathroom_centroids\n",
    "}\n",
    "\n",
    "G = centroids_to_graph(user_constraints, living_to_all=True)\n",
    "# draw_graph(G)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29f3ef39",
   "metadata": {
    "papermill": {
     "duration": 0.05316,
     "end_time": "2023-04-16T07:06:28.314088",
     "exception": false,
     "start_time": "2023-04-16T07:06:28.260928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='archi'></a>\n",
    "### Architecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f23c802",
   "metadata": {},
   "source": [
    "> Converting graphs to pytorch geometric graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "74758c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boundary graph\n",
    "B_pytorch = from_networkx(boundary_graph, group_node_attrs=['type', 'centroid'], group_edge_attrs=['distance'])\n",
    "\n",
    "# Floor plan graph\n",
    "features = ['roomType_embd', 'actualCentroid_x', 'actualCentroid_y']\n",
    "G_pytorch = from_networkx(G, group_edge_attrs=['distance'], group_node_attrs=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7bc7df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_x = G_pytorch.x[:, 1].mean().item()\n",
    "mean_y = G_pytorch.x[:, 2].mean().item()\n",
    "\n",
    "std_x = G_pytorch.x[:, 1].std().item()\n",
    "std_y = G_pytorch.x[:, 2].std().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f2538e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2635,\n",
       "         -0.3450],\n",
       "        [ 0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.1641,\n",
       "          0.5930],\n",
       "        [ 0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.1211,\n",
       "         -1.1851],\n",
       "        [ 0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -1.6795,\n",
       "          0.6242],\n",
       "        [ 0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.1516,\n",
       "         -1.4659],\n",
       "        [ 0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.1732,\n",
       "          0.8426],\n",
       "        [ 0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000, -0.6670,\n",
       "          0.9362]], dtype=torch.float64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "for i in [1, 2]:\n",
    "    if i == 1:\n",
    "        G_pytorch.x[:, i] = (G_pytorch.x[:, i] - mean_x) / std_x\n",
    "    elif i == 2:\n",
    "        G_pytorch.x[:, i] = (G_pytorch.x[:, i] - mean_y) / std_y\n",
    "        \n",
    "first_column_encodings = F.one_hot(G_pytorch.x[:, 0].long(), num_classes=7).to(torch.float)\n",
    "G_pytorch.x = torch.cat([first_column_encodings, G_pytorch.x[:, 1:]], dim=1)\n",
    "\n",
    "G_pytorch.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8601daf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_bou_x = B_pytorch.x[:, 1].mean().item()\n",
    "mean_bou_y = B_pytorch.x[:, 2].mean().item()\n",
    "\n",
    "std_bou_x = B_pytorch.x[:, 1].std().item()\n",
    "std_bou_y = B_pytorch.x[:, 2].std().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c18e1cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -0.9350, -0.6026],\n",
       "        [ 0.0000, -0.5995, -0.6026],\n",
       "        [ 0.0000, -0.5995, -0.4890],\n",
       "        [ 0.0000,  0.3885, -0.4890],\n",
       "        [ 0.0000,  0.3885, -0.3471],\n",
       "        [ 0.0000,  1.5256, -0.3471],\n",
       "        [ 0.0000,  1.5256,  1.7544],\n",
       "        [ 0.0000, -0.9350,  1.7544],\n",
       "        [ 1.0000, -0.7590, -0.6313]], dtype=torch.float64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "for i in [1, 2]:\n",
    "    if i == 1:\n",
    "        B_pytorch.x[:, i] = (B_pytorch.x[:, i] - mean_bou_x) / std_bou_x\n",
    "    elif i == 2:\n",
    "        B_pytorch.x[:, i] = (B_pytorch.x[:, i] - mean_bou_y) / std_bou_y\n",
    "        \n",
    "B_pytorch.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "58a7a8dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-16T07:06:28.421500Z",
     "iopub.status.busy": "2023-04-16T07:06:28.419439Z",
     "iopub.status.idle": "2023-04-16T07:06:31.330478Z",
     "shell.execute_reply": "2023-04-16T07:06:31.329316Z"
    },
    "papermill": {
     "duration": 2.96638,
     "end_time": "2023-04-16T07:06:31.332938",
     "exception": false,
     "start_time": "2023-04-16T07:06:28.366558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GATNet(\n",
       "  (graph_conv1): GATConv(9, 32, heads=4)\n",
       "  (graph_conv2): GATConv(137, 32, heads=8)\n",
       "  (graph_conv3): GATConv(265, 64, heads=8)\n",
       "  (graph_conv4): GATConv(521, 128, heads=8)\n",
       "  (boundary_conv1): GATConv(3, 32, heads=4)\n",
       "  (boundary_conv2): GATConv(131, 32, heads=8)\n",
       "  (Concatination1): GATConv(1292, 128, heads=8)\n",
       "  (width_layer1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (height_layer1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (width_output): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (height_output): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (boundary_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch.utils.data import Dataset\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "\n",
    "# For the GNN model\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv, global_mean_pool, global_max_pool\n",
    "\n",
    "\n",
    "class GATNet(torch.nn.Module):\n",
    "    def __init__(self, num_graph_node_features, num_boundary_node_features):\n",
    "        super(GATNet, self).__init__()\n",
    "        \n",
    "        self.graph_conv1 = GATConv(num_graph_node_features, 32, heads=4)\n",
    "        \n",
    "        input_of_conv2   = num_graph_node_features + 32*4\n",
    "        self.graph_conv2 = GATConv(input_of_conv2, 32, heads=8)\n",
    "        \n",
    "        input_of_conv3   = num_graph_node_features + 32*8\n",
    "        self.graph_conv3 = GATConv(input_of_conv3, 64, heads=8)\n",
    "        \n",
    "        input_of_conv4   = num_graph_node_features + 64*8\n",
    "        self.graph_conv4 = GATConv(input_of_conv4, 128, heads=8)\n",
    "        \n",
    "        shape_of_graphs_befor_concatination = num_graph_node_features + 128*8\n",
    "        \n",
    "        self.boundary_conv1 = GATConv(num_boundary_node_features, 32, heads=4)\n",
    "        input_of_boundary_conv2 = 32*4 + num_boundary_node_features\n",
    "        self.boundary_conv2 = GATConv(input_of_boundary_conv2, 32, heads=8)\n",
    "        \n",
    "        shape_of_boundary_befor_concatination = num_boundary_node_features + 32 * 8\n",
    "        \n",
    "        # Output of graph_conv8 + output of boundary_conv5 + 2 step connection from real nodes and boundary nodes\n",
    "        inputs_concatination = shape_of_graphs_befor_concatination + shape_of_boundary_befor_concatination\n",
    "        self.Concatination1  = GATConv(inputs_concatination, 128, heads=8)\n",
    "\n",
    "        self.width_layer1  = nn.Linear(128*8, 128)\n",
    "        self.height_layer1 = nn.Linear(128*8, 128)\n",
    "        \n",
    "        self.width_output  = nn.Linear(128, 1)\n",
    "        self.height_output = nn.Linear(128, 1)\n",
    "        \n",
    "        \n",
    "        self.boundary_pool = torch.nn.AdaptiveAvgPool1d(1)\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, graph, boundary):\n",
    "        x_graph, g_edge_index, g_edge_attr, g_batch = graph.x, graph.edge_index, graph.edge_attr, graph.batch\n",
    "        x_boundary, b_edge_indexy, b_edge_attr, b_batch = boundary.x, boundary.edge_index, boundary.edge_attr, boundary.batch\n",
    "        \n",
    "        NUM_OF_NODES = x_graph.shape[0]\n",
    "        # During testing, as we input only one graph.\n",
    "        if g_batch == None:\n",
    "            g_batch = torch.zeros(x_graph.shape[0], dtype=torch.long)\n",
    "        if b_batch == None:\n",
    "            b_batch = torch.zeros(x_boundary.shape[0], dtype=torch.long)\n",
    "        \n",
    "        \n",
    "        x_graph_res = x_graph\n",
    "        x_boundary_res = x_boundary\n",
    "        \n",
    "        # Passing the graph throught a message passing to embed its features\n",
    "        x_graph = F.leaky_relu(self.graph_conv1(x_graph, g_edge_index, g_edge_attr))\n",
    "        x_graph = self.dropout(x_graph) # Concatinate with step connection from real values.\n",
    "        x_graph = torch.cat([x_graph, x_graph_res], dim=1)\n",
    "        \n",
    "        \n",
    "        x_graph = F.leaky_relu(self.graph_conv2(x_graph, g_edge_index, g_edge_attr))\n",
    "        x_graph = self.dropout(x_graph)\n",
    "        x_graph = torch.cat([x_graph, x_graph_res], dim=1)\n",
    "        \n",
    "        x_graph = F.leaky_relu(self.graph_conv3(x_graph, g_edge_index))\n",
    "        x_graph = self.dropout(x_graph) \n",
    "        x_graph = torch.cat([x_graph, x_graph_res], dim=1)\n",
    "        \n",
    "        x_graph = F.leaky_relu(self.graph_conv4(x_graph, g_edge_index))\n",
    "        x_graph = self.dropout(x_graph) \n",
    "        x_graph = torch.cat([x_graph, x_graph_res], dim=1)\n",
    "        \n",
    "        # Passing the boundary throught a message passing to embed its features\n",
    "        x_boundary = F.leaky_relu(self.boundary_conv1(x_boundary, b_edge_indexy, b_edge_attr))\n",
    "        x_boundary = self.dropout(x_boundary)\n",
    "        x_boundary = torch.cat([x_boundary, x_boundary_res], dim=1)\n",
    "        \n",
    "        x_boundary = F.leaky_relu(self.boundary_conv2(x_boundary, b_edge_indexy, b_edge_attr))\n",
    "        x_boundary = self.dropout(x_boundary)\n",
    "        x_boundary = torch.cat([x_boundary, x_boundary_res], dim=1)\n",
    "\n",
    "        # Pooling the bounadry to 1D vector by getting max value in each feature for all nodes.\n",
    "        x_boundary_pooled = F.max_pool1d(x_boundary.transpose(0, 1), kernel_size=x_boundary.shape[0]).view(1, -1)\n",
    "        \n",
    "        # Concatinating the graph & the boundary\n",
    "        x = torch.cat([x_graph, x_boundary_pooled.repeat(NUM_OF_NODES, 1)], dim=1)\n",
    "        x = F.leaky_relu(self.Concatination1(x, g_edge_index))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        \n",
    "        width = F.leaky_relu(self.width_layer1(x))\n",
    "        width = self.dropout(width)\n",
    "        width = self.width_output(width)\n",
    "        \n",
    "        height = F.leaky_relu(self.height_layer1(x))\n",
    "        height = self.dropout(height)\n",
    "        height = self.height_output(height)\n",
    "        \n",
    "        return width.squeeze(), height.squeeze()\n",
    "\n",
    "num_graph_node_features = G_pytorch.x.shape[1]\n",
    "num_boundary_node_features = B_pytorch.x.shape[1]\n",
    "\n",
    "model = GATNet(num_graph_node_features, num_boundary_node_features)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# to monitor the loss & accuracy.\n",
    "errors = []\n",
    "acc = []\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ffd9a9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GATNet(\n",
       "  (graph_conv1): GATConv(9, 32, heads=4)\n",
       "  (graph_conv2): GATConv(137, 32, heads=8)\n",
       "  (graph_conv3): GATConv(265, 64, heads=8)\n",
       "  (graph_conv4): GATConv(521, 128, heads=8)\n",
       "  (boundary_conv1): GATConv(3, 32, heads=4)\n",
       "  (boundary_conv2): GATConv(131, 32, heads=8)\n",
       "  (Concatination1): GATConv(1292, 128, heads=8)\n",
       "  (width_layer1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (height_layer1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (width_output): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (height_output): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (boundary_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = r\"Regressions\\squares_w_h\\checkpoints\\v2\\Best_model_V2.pt\"\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epochs = checkpoint['epoch']\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4430946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FloorPlan_multipolygon():\n",
    "    def __init__(self, graph, prediction=None):\n",
    "        self.graph       = graph\n",
    "        self.prediction  = prediction\n",
    "        \n",
    "    def get_room_data(self, room_index):\n",
    "        \"\"\"\n",
    "        Inputs: \n",
    "            room_index: index of the room in the graph\n",
    "            \n",
    "        Outputs: \n",
    "            centroid, w, h of that room.\n",
    "        \"\"\"\n",
    "        # # Using networkX graphs\n",
    "        # Graph_data = list(self.graph.nodes(data=True))[room_index][1]\n",
    "        # w = Graph_data['rec_w']\n",
    "        # h = Graph_data['rec_h']\n",
    "        # centroid = (Graph_data['actualCentroid_x'], Graph_data['actualCentroid_y'])\n",
    "        # category = Graph_data['roomType_embd']\n",
    "        \n",
    "        # Using pytorhc Garphs\n",
    "        w = self.graph.rec_w[room_index].item()\n",
    "        h = self.graph.rec_h[room_index].item()\n",
    "        centroid = (self.graph.x[room_index][-2].item(), self.graph.x[room_index][-1].item())\n",
    "        category = torch.argmax(self.graph.x[:, :7][room_index]).item()\n",
    "        \n",
    "        if isinstance(self.prediction, np.ndarray): # A  real array of predictions\n",
    "            w_pre, h_pre = self.get_predictions(room_index)\n",
    "            \n",
    "        else:\n",
    "            w_pre, h_pre = None, None\n",
    "            \n",
    "        data = {\n",
    "            'centroid': centroid,\n",
    "            'real_w': w,\n",
    "            'real_h': h, \n",
    "            'predic_w': w_pre,\n",
    "            'predic_h': h_pre,\n",
    "            'category': category\n",
    "        }\n",
    "        return data\n",
    "    \n",
    "    def create_box(self, room_data):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            room_data: a dictionary with centroid, w, h of that room.\n",
    "            \n",
    "        Outputs:\n",
    "            box: a shapely box with the same centroid, w, h of that room.\n",
    "        \"\"\"\n",
    "        \n",
    "        centroid = room_data['centroid']\n",
    "        # print(centroid)\n",
    "        if isinstance(self.prediction, np.ndarray): # A  real array of predictions\n",
    "            half_w   = room_data['predic_w'] / 2\n",
    "            half_h   = room_data['predic_h'] / 2\n",
    "        \n",
    "        else:\n",
    "            half_w   = room_data['real_w'] / 2\n",
    "            half_h   = room_data['real_h'] / 2\n",
    "\n",
    "        bottom_left  = Point(centroid[0] - half_w, centroid[1] - half_h)\n",
    "        bottom_right = Point(centroid[0] + half_w, centroid[1] - half_h)\n",
    "        top_right    = Point(centroid[0] + half_w, centroid[1] + half_h)\n",
    "        top_left     = Point(centroid[0] - half_w, centroid[1] + half_h)\n",
    "        \n",
    "        box = Polygon([bottom_left, bottom_right, top_right, top_left])\n",
    "        return box\n",
    "\n",
    "    def get_multipoly(self):\n",
    "        \"\"\"\n",
    "        Outputs:\n",
    "            multi_poly: a shapely multipolygon of all the rooms in the floor plan or graph.\n",
    "        \"\"\"\n",
    "        num_of_rooms = self.graph.x.shape[0]\n",
    "        similar_polygons = defaultdict(list)\n",
    "        \n",
    "        for index in range(num_of_rooms):\n",
    "            room_data = self.get_room_data(index)\n",
    "            box = self.create_box(room_data)\n",
    "            \n",
    "            # add each pox to its similar boxes\n",
    "            similar_polygons[room_data['category']].append(box)\n",
    "            \n",
    "        all_polygons = []\n",
    "        for _, polygons in similar_polygons.items():\n",
    "            all_polygons.append(MultiPolygon(polygons))\n",
    "            \n",
    "        compined_polygons_seperated = gpd.GeoSeries(all_polygons)\n",
    "        \n",
    "        return compined_polygons_seperated\n",
    "    \n",
    "    def get_predictions(self, room_index):\n",
    "        \"\"\"\n",
    "        Inputs: \n",
    "            room_index: index of the room in the graph\n",
    "        outputs: \n",
    "            w_predicted: predicted width for that room\n",
    "            h_predicted: predicted width for that room\n",
    "        \"\"\"\n",
    "        w_predicted = self.prediction[:, 0]\n",
    "        h_predicted = self.prediction[:, 1]\n",
    "        \n",
    "        return w_predicted[room_index], h_predicted[room_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c1098ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_pytorch.x = B_pytorch.x.to(G_pytorch.x)\n",
    "B_pytorch.edge_index = B_pytorch.edge_index.to(G_pytorch.edge_index)\n",
    "B_edge_attr = B_pytorch.edge_attr.to(G_pytorch.edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3d83e1b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Double but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[114], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m prediction \u001b[39m=\u001b[39m model(G_pytorch\u001b[39m.\u001b[39;49mto(device), B_pytorch\u001b[39m.\u001b[39;49mto(device))\n",
      "File \u001b[1;32mc:\\Users\\zmlka\\anaconda3\\envs\\torch2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[108], line 67\u001b[0m, in \u001b[0;36mGATNet.forward\u001b[1;34m(self, graph, boundary)\u001b[0m\n\u001b[0;32m     64\u001b[0m x_boundary_res \u001b[39m=\u001b[39m x_boundary\n\u001b[0;32m     66\u001b[0m \u001b[39m# Passing the graph throught a message passing to embed its features\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m x_graph \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mleaky_relu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgraph_conv1(x_graph, g_edge_index, g_edge_attr))\n\u001b[0;32m     68\u001b[0m x_graph \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(x_graph) \u001b[39m# Concatinate with step connection from real values.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m x_graph \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([x_graph, x_graph_res], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zmlka\\anaconda3\\envs\\torch2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\zmlka\\anaconda3\\envs\\torch2\\lib\\site-packages\\torch_geometric\\nn\\conv\\gat_conv.py:213\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[1;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, Tensor):\n\u001b[0;32m    212\u001b[0m     \u001b[39massert\u001b[39;00m x\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mStatic graphs not supported in \u001b[39m\u001b[39m'\u001b[39m\u001b[39mGATConv\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 213\u001b[0m     x_src \u001b[39m=\u001b[39m x_dst \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlin_src(x)\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, H, C)\n\u001b[0;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# Tuple of source and target node features:\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     x_src, x_dst \u001b[39m=\u001b[39m x\n",
      "File \u001b[1;32mc:\\Users\\zmlka\\anaconda3\\envs\\torch2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\zmlka\\anaconda3\\envs\\torch2\\lib\\site-packages\\torch_geometric\\nn\\dense\\linear.py:132\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    128\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39m        x (torch.Tensor): The input features.\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"
     ]
    }
   ],
   "source": [
    "prediction = model(G_pytorch.to(device), B_pytorch.to(device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17190.24346,
   "end_time": "2023-04-16T11:50:47.981067",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-16T07:04:17.737607",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
