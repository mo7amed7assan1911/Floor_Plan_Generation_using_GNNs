{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88f1eb50",
   "metadata": {},
   "source": [
    "# Planify - Graph Neural Network\n",
    "\n",
    "### Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#intro\">Introduction</a></li>\n",
    "    <ul>\n",
    "        <li><a href=\"#Imports\">Imports</a></li>\n",
    "        <li><a href=\"#func\">Functions used</a></li>\n",
    "    </ul>\n",
    "<li><a href=\"#wrangling\">Data Wrangling</a></li>\n",
    "<li><a href=\"#model\">GNN Model</a></li>\n",
    "    <ul>\n",
    "        <li><a href=\"#dataLoader\">Data Loader</a></li>\n",
    "        <li><a href=\"#archi\">Architecture</a></li>\n",
    "        <li><a href=\"#train\">Training</a></li> \n",
    "        <li><a href=\"#eval\">Evaluation</a></li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c612d2c6",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "> This notebook getting garphs in the Networkx format from the `Creating Graphs` notebook. And its main goal is to make the GNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "849fb853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for vsCode only to show tqdm process\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52912620",
   "metadata": {},
   "source": [
    "<a id='Imports'></a>\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ef47335",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Only for kaggle\n",
    "# !pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67cc3944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Not included packages in kaggle\n",
    "\n",
    "# Install torch_geometric\n",
    "# !pip install /kaggle/input/torch-geometric/torch_sparse-0.6.16-cp37-cp37m-linux_x86_64.whl -q\n",
    "# !pip install /kaggle/input/torch-geometric/torch_scatter-2.1.0-cp37-cp37m-linux_x86_64.whl -q\n",
    "\n",
    "# # # library for getting distinct colores\n",
    "# !pip install distinctipy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21f601a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for data wrangling\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import distinctipy\n",
    "import random\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "# to show advance in for loops\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Using pytorch geometric\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch.utils.data import Dataset\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "\n",
    "# For the GNN model\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv, global_mean_pool, global_max_pool\n",
    "\n",
    "\n",
    "# for my pc [linux]\n",
    "# url = '/media/mo/DATA/Grad/Planify_Dataset/Graph/Planify_Graphs.pkl'\n",
    "\n",
    "# for my pc [windows]\n",
    "# url = \"D:\\Grad\\Planify_Dataset\\Graph\\Planify_Graphs.pkl\"\n",
    "url_real = \"D:\\Grad\\Planify_Dataset\\Planify_Graphs\\Graphs_real.pkl\"\n",
    "url_all_toLiving = \"D:\\Grad\\Planify_Dataset\\Planify_Graphs\\Graphs_living_to_all.pkl\"\n",
    "# url_boundary = r\"D:\\Grad\\Planify_Dataset\\Graph\\graphs\\boundaries.pkl\"\n",
    "\n",
    "# for kaggle\n",
    "# url_all_toLiving = \"/kaggle/input/planify-graphs-all-forms/Planify_Graphs_no_balacony_inner_centroid_used/Planify_Graphs/Graphs_living_to_all.pkl\"\n",
    "# url_boundary = \"/kaggle/input/planify-graphs-all-forms/Planify_Graphs_no_balacony_inner_centroid_used/Planify_Graphs/Graphs_real.pkl\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d993568d",
   "metadata": {},
   "source": [
    "<a id='func'></a>\n",
    "### Functions used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "441cb7a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geoms_columns = ['inner', 'living', 'master', 'kitchen', 'bathroom', 'dining', 'child', 'study',\n",
    "                   'second_room', 'guest', 'balcony', 'storage', 'wall-in',\n",
    "                    'outer_wall', 'front', 'inner_wall', 'interior',\n",
    "                   'front_door', 'outer_wall', 'entrance']\n",
    "\n",
    "N = len(geoms_columns)\n",
    "colors = (np.array(distinctipy.get_colors(N)) * 255).astype(np.uint8)\n",
    "room_color = {room_name: colors[i] for i, room_name in enumerate(geoms_columns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf9a39e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def draw_graph(G):\n",
    "    #  nodes positions for drawing, note that we invert the y pos\n",
    "    pos = {node: (G.nodes[node]['actualCentroid_x'], -G.nodes[node]['actualCentroid_y']) for node in G.nodes}\n",
    "    \n",
    "    scales = [G.nodes[node]['roomSize'] * 10000 for node in G] \n",
    "    colormap = [room_color[G.nodes[node]['roomType_name']]/255 for node in G]\n",
    "    \n",
    "    nx.draw(G, pos=pos, node_size=scales, node_color=colormap, with_labels=True, font_size=12)\n",
    "    \n",
    "    # Drawing the graph inside a good boundary.\n",
    "    x_coords  = [pos[node][0] for node in pos]\n",
    "    y_coords  = [pos[node][1] for node in pos]\n",
    "    threshold = max(scales) / 100\n",
    "    \n",
    "    plt.xlim(min(x_coords) - threshold, max(x_coords) + threshold)\n",
    "    plt.ylim(min(y_coords) - threshold, max(y_coords) + threshold)\n",
    "\n",
    "def draw_graph_boundary(G):\n",
    "    #  nodes positions for drawing, note that we invert the y pos\n",
    "    pos = {node: (G.nodes[node]['centroid'][0], -G.nodes[node]['centroid'][1])  for node in G.nodes}\n",
    "    \n",
    "    door_color = '#90EE90'\n",
    "    other_nodes_color = '#0A2A5B'\n",
    "    color_map = [door_color if G.nodes[node]['type'] == 1 else other_nodes_color for node in G.nodes]\n",
    "    \n",
    "    nx.draw(G, pos=pos, with_labels=True, node_color=color_map, font_color='w', font_size=12)\n",
    "\n",
    "# For statistics\n",
    "def get_max_min_x_y(graphs):\n",
    "    max_x = 0\n",
    "    max_y = 0\n",
    "    min_x = float('inf')\n",
    "    min_y = float('inf')\n",
    "    \n",
    "    for G in tqdm(graphs, desc=\"Getting maximum x, y\", total=len(graphs)):\n",
    "        max_x_in_graph = G.x.T[1].max().item()\n",
    "        max_y_in_graph = G.x.T[2].max().item()\n",
    "        \n",
    "        min_x_in_graph = G.x.T[1].min().item()\n",
    "        min_y_in_graph = G.x.T[2].min().item()\n",
    "        \n",
    "        if max_x_in_graph > max_x:\n",
    "            max_x = max_x_in_graph\n",
    "        if max_y_in_graph > max_y:\n",
    "            max_y = max_y_in_graph\n",
    "            \n",
    "        if min_x_in_graph < min_x:\n",
    "            min_x = min_x_in_graph\n",
    "        if min_y_in_graph < min_y:\n",
    "            min_y = min_y_in_graph\n",
    "            \n",
    "    values = {'max_x': max_x, 'max_y': max_y, 'min_x': min_x, 'min_y': min_y}\n",
    "    return values\n",
    "\n",
    "def get_all_x_y(graphs):\n",
    "    \"\"\"Get all values of x and y from all graphs\n",
    "        Input: list of graphs\n",
    "        Output: x and y as pandas series\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for G in tqdm(graphs, desc=\"getting all Xs, Ys\", total=len(graphs)):\n",
    "        for i in range(len(G.x)):\n",
    "            x.append(G.x[i][1].item())\n",
    "            y.append(G.x[i][2].item())\n",
    "\n",
    "    x = pd.Series(x)\n",
    "    y = pd.Series(y)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def boxplot_centrValues(x, y):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Plot the boxplots\n",
    "    ax.boxplot([x, y])\n",
    "\n",
    "    # Set the xtick labels\n",
    "    ax.set_xticklabels(['x', 'y'])\n",
    "\n",
    "    # Add axis labels and title\n",
    "    ax.set_xlabel('Data')\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.set_title('Boxplot of x and y in all graphs')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    \n",
    "def plot_histograms(x, y):\n",
    "    x.hist(density=True, bins=100, alpha=0.6, label='x');\n",
    "    y.hist(density=True, bins=100, alpha=0.3, label='y');\n",
    "    plt.legend();\n",
    "    plt.title('Distribution of x and y');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2519899",
   "metadata": {},
   "source": [
    "<a id='wrangling'></a>\n",
    "## Data wrangling\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d5d1757",
   "metadata": {},
   "source": [
    "### Real Graphs pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81a204b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 8 nodes and 13 edges\n"
     ]
    }
   ],
   "source": [
    "with open(url_real, 'rb') as f:\n",
    "    real_graphs = pickle.load(f)\n",
    "    \n",
    "G = real_graphs[1911]\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d679b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80787/80787 [03:44<00:00, 360.01it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 16], roomType_name=[6], rec_w=[6], rec_h=[6], roomSize=[6], x=[6, 3], edge_attr=[16, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting networkx graphs to pytorchGeo graphs\n",
    "features = ['roomType_embd', 'actualCentroid_x', 'actualCentroid_y']\n",
    "real_graphs_pyTorch = []\n",
    "for G in tqdm(real_graphs):\n",
    "    G_new = from_networkx(G, group_node_attrs=features, group_edge_attrs=['distance'])\n",
    "    # Normalizing feature matrix (x)\n",
    "    # G_new = T.NormalizeFeatures()(G_new)\n",
    "    \n",
    "    real_graphs_pyTorch.append(G_new)\n",
    "\n",
    "real_graphs_pyTorch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcf8f2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "getting all Xs, Ys: 100%|██████████| 80787/80787 [00:21<00:00, 3804.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(234.5, 234.0, 20.0, 20.5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = get_all_x_y(real_graphs_pyTorch)\n",
    "x.max(), y.max(), x.min(), y.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0b977d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# making box plot for x and y for the graphs\n",
    "boxplot_centrValues(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3f90f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj4AAAGxCAYAAABiPLw8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABNsUlEQVR4nO3dfVyUVf4//tc4DAMYeIPCDKsguJYadjf4QdgItRjFsk2x2Ozj6qZuLJYB67dEc0W3xFzWBx8f3rAV3q2p7K5atlIyrkK6jq2LWKTmh/3FjRkTQSomCgOc3x9+mBpmgJkRmGGu1/PxmIfMud7XOee6zgy8PdedTAghQERERCQB/ZzdASIiIqLewsSHiIiIJIOJDxEREUkGEx8iIiKSDCY+REREJBlMfIiIiEgymPgQERGRZDDxISIiIslg4kNERESSwcSHyMm2b98OmUxmenl5eUGlUmHSpEnIzMxETU2NxToZGRmQyWR2tdPQ0ICMjAwUFhbatZ61tkaMGIEnnnjCrnq6snv3bmRnZ1tdJpPJkJGR0a3tdbd//OMfiIiIQP/+/SGTyfDee+85u0t3pO1zWVFR4eyuEHUrD2d3gIhu27ZtG0aPHg2j0YiamhqcOHECb775JrKyspCXl4fHHnvMFLtgwQJMnTrVrvobGhqwatUqAMDEiRNtXs+Rthyxe/dufP7550hJSbFYptfrMWzYsB7vg6OEEHjmmWdw99134+DBg+jfvz/uueceZ3eLiKxg4kPkIsLDwxEREWF6n5CQgNTUVDz88MOYOXMmysrKEBgYCAAYNmxYjycCDQ0N8PHx6ZW2ujJhwgSntt+Vr7/+Gt999x1mzJiBRx991NndIaJO8FAXkQsLDg7GH//4R1y/fh1/+tOfTOXWDj8dPXoUEydOhL+/P7y9vREcHIyEhAQ0NDSgoqICQ4cOBQCsWrXKdFht3rx5ZvWdOXMGs2bNwqBBgzBy5MgO22pz4MAB3HffffDy8kJYWBg2bNhgtryjwyWFhYWQyWSmw24TJ07EoUOHUFlZaXbYr421Q12ff/45fv7zn2PQoEHw8vLCAw88gB07dlhtZ8+ePVi+fDmCgoLg5+eHxx57DBcvXux4x//IiRMn8Oijj8LX1xc+Pj6Ijo7GoUOHTMszMjJMieGrr74KmUyGESNGdFhfUlISvLy8UFxcbCprbW3Fo48+isDAQFRXV3fan1WrViEyMhKDBw+Gn58fHnroIeTm5qL986bbDkd+9NFHeOihh+Dt7Y3Ro0dj69atFnWeOnUKP/vZz+Dl5YWgoCCkp6fDaDR2uW/+/Oc/QyaTQa/XWyxbvXo1FAoFvv766y7rIepNTHyIXNy0adMgl8vx8ccfdxhTUVGBxx9/HJ6enti6dSs++ugjrF27Fv3790dTUxPUajU++ugjAMD8+fOh1+uh1+uxYsUKs3pmzpyJn/70p/jrX/+KnJycTvt19uxZpKSkIDU1FQcOHEB0dDRefvllZGVl2b2Nmzdvxs9+9jOoVCpT36z9MW1z8eJFREdH49y5c9iwYQP279+PsWPHYt68eVi3bp1F/LJly1BZWYl33nkHb731FsrKyjB9+nS0tLR02q+ioiJMnjwZ165dQ25uLvbs2QNfX19Mnz4deXl5AG4fCty/fz8A4KWXXoJer8eBAwc6rDM7OxtjxozBM888g6tXrwK4ncwUFhZi165dUKvVnfapoqICL7zwAv7yl79g//79mDlzJl566SX8/ve/t4j99NNP8dvf/hapqal4//33cd9992H+/Plmn6Xz58/j0UcfxdWrV7F9+3bk5OSgpKQEr7/+eqf9AIDExESoVCps2rTJrLy5uRl/+tOfMGPGDAQFBXVZD1GvEkTkVNu2bRMAxOnTpzuMCQwMFGPGjDG9X7lypfjx1/dvf/ubACDOnj3bYR3ffvutACBWrlxpsaytvt/97ncdLvuxkJAQIZPJLNqLi4sTfn5+4saNG2bbVl5ebhZ37NgxAUAcO3bMVPb444+LkJAQq31v3+9f/OIXQqlUiqqqKrO4+Ph44ePjI65evWrWzrRp08zi/vKXvwgAQq/XW22vzYQJE0RAQIC4fv26qay5uVmEh4eLYcOGidbWViGEEOXl5QKA+MMf/tBpfW3KysqEn5+feOqpp8SRI0dEv379xGuvvWbTuj/W0tIijEajWL16tfD39zf1R4jbY+Tl5SUqKytNZTdv3hSDBw8WL7zwgqksMTFReHt7C4PBYLaNo0ePtjp27a1cuVJ4enqKb775xlSWl5cnAIiioiK7t4mop3HGh6gPEO0OY7T3wAMPwNPTE7/+9a+xY8cOfPnllw61k5CQYHPsvffei/vvv9+sbPbs2aivr8eZM2ccat9WR48exaOPPorhw4eblc+bNw8NDQ0Ws0VPPvmk2fv77rsPAFBZWdlhGzdu3MAnn3yCWbNm4a677jKVy+VyzJkzB1999ZXNh8va++lPf4q3334b7733Hp544gnExMTYfNXa0aNH8dhjj2HAgAGQy+VQKBT43e9+h7q6OosrAB944AEEBweb3nt5eeHuu+822+5jx46ZDrP9eBsTExNt6s9vfvMbAMDbb79tKtu4cSPGjRuHRx55xKY6iHoTEx8iF3fjxg3U1dV1eshg5MiROHLkCAICArBo0SKMHDkSI0eOxP/8z//Y1VZXh1l+TKVSdVhWV1dnV7v2qqurs9rXtn3Uvn1/f3+z90qlEgBw8+bNDtu4cuUKhBB2tWOPxx9/HIGBgbh16xbS0tIgl8u7XOdf//oXtFotgNuJxj//+U+cPn0ay5cvB2C5Pe23G7i97T+Oq6ur63QsuxIYGIjExET86U9/QktLCz777DMcP34cL774ok3rE/U2Jj5ELu7QoUNoaWnp8hL0mJgYfPDBB7h27RpOnTqFqKgopKSkYO/evTa3Zc+9gQwGQ4dlbX9wvby8AACNjY1mcbW1tTa3Y42/v7/Vk4DbTqQdMmTIHdUPAIMGDUK/fv16rJ2kpCRcv34d9957LxYvXowrV650uc7evXuhUCjw97//Hc888wyio6PNrgR0hL+/f6djaYuXX34Zly5dwvvvv4+NGzdi4MCBeO655+6oX0Q9hYkPkQurqqrCkiVLMGDAALzwwgs2rSOXyxEZGWk64bTtsJMtsxz2OHfuHD799FOzst27d8PX1xcPPfQQAJiubvrss8/M4g4ePGhRX/uZiM48+uijOHr0qMUVQzt37oSPj0+3XP7ev39/REZGYv/+/Wb9am1txa5duzBs2DDcfffdDtX9zjvvYNeuXdi4cSMOHjyIq1ev4le/+lWX68lkMnh4eJjNDt28eRN//vOfHeoHAEyaNAn/+Mc/8M0335jKWlpaTCdv20Kj0SA6Ohpvvvkm3n33XcybNw/9+/d3uE9EPYn38SFyEZ9//jmam5vR3NyMmpoaHD9+HNu2bYNcLseBAwdMl6Nbk5OTg6NHj+Lxxx9HcHAwbt26Zbpsue3Gh76+vggJCcH777+PRx99FIMHD8aQIUM6vfS6M0FBQXjyySeRkZEBtVqNXbt2QafT4c0334SPjw8AYPz48bjnnnuwZMkSNDc3Y9CgQThw4ABOnDhhUd+4ceOwf/9+bNmyBRqNBv369etwNmPlypX4+9//jkmTJuF3v/sdBg8ejHfffReHDh3CunXrMGDAAIe2qb3MzEzExcVh0qRJWLJkCTw9PbF582Z8/vnn2LNnj913zwaA0tJSLF68GHPnzjUlO7m5uZg1axays7Ot3sCxzeOPP47169dj9uzZ+PWvf426ujpkZWWZklpHvPbaazh48CAmT56M3/3ud/Dx8cGmTZtw48YNu+p5+eWXkZiYCJlMhuTkZIf7Q9TjnH12NZHUtV351Pby9PQUAQEBIjY2VqxZs0bU1NRYrNP+Siu9Xi9mzJghQkJChFKpFP7+/iI2NlYcPHjQbL0jR46IBx98UCiVSgFAzJ0716y+b7/9tsu2hLh9xdDjjz8u/va3v4l7771XeHp6ihEjRoj169dbrP+///u/QqvVCj8/PzF06FDx0ksviUOHDllc1fXdd9+JWbNmiYEDBwqZTGbWJqxcjVZaWiqmT58uBgwYIDw9PcX9998vtm3bZhbTdlXXX//6V7Pytquw2sdbc/z4cTF58mTRv39/4e3tLSZMmCA++OADq/V1dVXX999/L0aPHi3Gjh1ruvKtzaJFi4RCoRCffPJJp3Vs3bpV3HPPPUKpVIqwsDCRmZkpcnNzLa7Aahuj9mJjY0VsbKxZ2T//+U8xYcIEoVQqhUqlEv/v//0/8dZbb9l0VVebxsZGoVQqxdSpU22KJ3IWmRBdXC5CRETUhQ8++ABPPvkkDh06hGnTpjm7O0QdYuJDREQOO3/+PCorK/Hyyy+jf//+OHPmjEOHAIl6C09uJiIihyUnJ+PJJ5/EoEGDHD7viag3ccaHiIiIJMOhGZ/NmzcjNDQUXl5e0Gg0OH78eKfxRUVF0Gg0pgcZtn8G0Ntvv42YmBgMGjQIgwYNwmOPPYZ//etfdrcrhEBGRgaCgoLg7e2NiRMn4ty5c45sIhEREbkhuxOfvLw8pKSkYPny5SgpKUFMTAzi4+NRVVVlNb68vBzTpk1DTEwMSkpKsGzZMixevBj79u0zxRQWFuLZZ5/FsWPHoNfrERwcDK1Wi8uXL9vV7rp167B+/Xps3LgRp0+fhkqlQlxcHK5fv27vZhIREZE7svcysP/6r/8SSUlJZmWjR48WS5cutRr/yiuviNGjR5uVvfDCC2LChAkdttHc3Cx8fX3Fjh07bG63tbVVqFQqsXbtWtPyW7duiQEDBoicnBzbNo6IiIjcml03MGxqakJxcTGWLl1qVq7VanHy5Emr6+j1etOzZdpMmTIFubm5MBqNUCgUFus0NDTAaDRi8ODBNrdbXl4Og8Fg1pZSqURsbCxOnjxp9a63jY2NZrfSb21txXfffQd/f3+eoEdERNRHCCFw/fp1BAUFoV+/zg9m2ZX41NbWoqWlxewpvsDth9R19FwXg8FgNb65uRm1tbVWHwC4dOlS/OQnPzHdcdaWdtv+tRbT0ROYMzMzsWrVqo42l4iIiPqQS5cuYdiwYZ3GOPTIivazIUKITmdIrMVbKwdun6ezZ88eFBYWmh5waE+79vQtPT0daWlppvfXrl1DcHAwysvL4evr2+H2kH2MRiOOHTuGSZMmWZ3hI+fjGLk+jpHr4xg5z/Xr1xEaGmrT3267Ep8hQ4ZALpdbzO7U1NRYzLS0UalUVuM9PDxMT3Buk5WVhTVr1uDIkSO477777GpXpVIBuD3z8+NZpM76plQqrT7jZvDgwfDz87O6DtnPaDTCx8cH/v7+/GXgojhGro9j5Po4Rs7Ttr9tOU3Frqu6PD09odFooNPpzMp1Oh2io6OtrhMVFWURX1BQgIiICLMPxh/+8Af8/ve/x0cffWTxYEJb2g0NDYVKpTKLaWpqQlFRUYd9IyIiImmx+1BXWloa5syZg4iICERFReGtt95CVVUVkpKSANw+fHT58mXs3LkTAJCUlISNGzciLS0NCxcuhF6vR25uLvbs2WOqc926dVixYgV2796NESNGmGZ27rrrLtx11102tSuTyZCSkoI1a9Zg1KhRGDVqFNasWQMfHx/Mnj37zvYSERERuQW7E5/ExETU1dVh9erVqK6uRnh4OPLz8xESEgIAqK6uNru3TmhoKPLz85GamopNmzYhKCgIGzZsQEJCgilm8+bNaGpqwqxZs8zaWrlyJTIyMmxqFwBeeeUV3Lx5E8nJybhy5QoiIyNRUFDA83WIiIgIAB9ZYaa+vh4DBgzAtWvXeI5PNzIajcjPz8e0adN43NtFcYxcH8fI9Tl7jIQQaG5uRktLS6+33Rvkcjk8PDysnsdjz99vh67qIiIiItfR1NSE6upqNDQ0OLsrPcrHxwdqtRqenp4O18HEh4iIqA9rbW1FeXk55HI5goKC4Onp6XY34RVCoKmpCd9++y3Ky8sxatSoLm9U2BEmPkRERH1YU1MTWltbMXz4cPj4+Di7Oz3G29sbCoUClZWVaGpqsrjXn60cS5eIiIjIpTg6A9KXdMc2uv9eIiIiIvo/THyIiIhIMniODxERkZtK31/aq+1lzhzXq+05gjM+REREJBlMfIiIiEgymPgQERFRr/v222+hUqmwZs0aU9knn3wCT09PFBQU9Fi7PMeHiCTD2vkOfeGcBCJ3NHToUGzduhVPPfUUtFotRo8ejf/+7/9GcnIytFptj7XLxIeIiIicYtq0aVi4cCGee+45jB8/Hl5eXli7dm2PtslDXUREROQ0WVlZaG5uxl/+8he8++67Dt+R2VZMfIiIiMhpvvzyS3z99ddobW1FZWVlj7fHQ11ERETkFE1NTXjuueeQmJiI0aNHY/78+SgtLUVgYGCPtckZHyIiInKK5cuX49q1a9iwYQNeeeUVjBkzBvPnz+/RNjnjQ0RE5KZc+arFwsJCZGdn49ixY/Dz8wMA/PnPf8Z9992HLVu24De/+U2PtMvEh4iIiHrdxIkTYTQazcqCg4Nx9erVHm2Xh7qIiIhIMpj4EBERkWQw8SEiIiLJYOJDREREksHEh4iIiCSDiQ8RERFJBhMfIiIikgwmPkRERCQZTHyIiIhIMnjnZiIiInd18cPebe+e+N5tzwGc8SEiIiLJYOJDREREksHEh4iIiHrdzp074e/vj8bGRrPyhIQE/PKXv+yxdpn4EBERUa97+umn0dLSgoMHD5rKamtr8fe//x2/+tWveqxdJj5ERETU67y9vTF79mxs27bNVPbuu+9i2LBhmDhxYo+1y8SHiIiInGLhwoUoKCjA5cuXAQDbtm3DvHnzIJPJeqxNJj5ERETkFA8++CDuv/9+7Ny5E2fOnEFpaSnmzZvXo206lPhs3rwZoaGh8PLygkajwfHjxzuNLyoqgkajgZeXF8LCwpCTk2O2/Ny5c0hISMCIESMgk8mQnZ1tUUfbsvavRYsWmWLassQfvyZMmODIJhIREVEvWLBgAbZt24atW7fisccew/Dhw3u0PbsTn7y8PKSkpGD58uUoKSlBTEwM4uPjUVVVZTW+vLwc06ZNQ0xMDEpKSrBs2TIsXrwY+/btM8U0NDQgLCwMa9euhUqlslrP6dOnUV1dbXrpdDoAt0+O+rGpU6eaxeXn59u7iURERNRLnnvuOVy+fBlvv/02nn/++R5vz+47N69fvx7z58/HggULAADZ2dk4fPgwtmzZgszMTIv4nJwcBAcHm2ZxxowZg3//+9/IyspCQkICAGD8+PEYP348AGDp0qVW2x06dKjZ+7Vr12LkyJGIjY01K1cqlR0mT0RERJLSB+6k7Ofnh4SEBBw6dAhPPfVUj7dnV+LT1NSE4uJii+REq9Xi5MmTVtfR6/XQarVmZVOmTEFubi6MRiMUCoWdXb7dj127diEtLc3iBKjCwkIEBARg4MCBiI2NxRtvvIGAgACr9TQ2NprdP6C+vh4AYDQaYTQa7e4XWde2L7lPXZdUxkiOVouyvrLNUhmjvsxZY2Q0GiGEQGtrK1pbLT/jfcHXX3+N2bNnQ6FQdLoNra2tEELAaDRCLpebyu3Z53YlPrW1tWhpaUFgYKBZeWBgIAwGg9V1DAaD1fjm5mbU1tZCrVbb0wUAwHvvvYerV69anAAVHx+Pp59+GiEhISgvL8eKFSswefJkFBcXQ6lUWtSTmZmJVatWWZQXFBTAx8fH7n5R59oOT5LrcvcxGi+3LMvPr+j1ftwJdx8jd9DbY+Th4QGVSoXvv/8eTU1Nvdr2nbpy5QqOHj2KY8eOITMz0zQB0ZGmpibcvHkTH3/8MZqbm03lDQ0NNrfp0ENK28+yCCE6vfTMWry1clvl5uYiPj4eQUFBZuWJiYmmn8PDwxEREYGQkBAcOnQIM2fOtKgnPT0daWlppvf19fUYPnw4tFot/Pz8HOobWTIajdDpdIiLi3Noho96nlTGaNUH5y3KVk4f64Se2E8qY9SXOWuMbt26hUuXLuGuu+6Cl5dXr7XbHR544AFcuXIFa9euhUaj6TL+1q1b8Pb2xiOPPGK2rV0lTD9mV+IzZMgQyOVyi9mdmpoai1mdNiqVymq8h4cH/P397WkeAFBZWYkjR45g//79Xcaq1WqEhISgrKzM6nKlUml1JkihUPAXSw/gfnV97j5GLVau5+hr2+vuY+QOenuMWlpaIJPJ0K9fP/Tr17fuUlNRUWFXfL9+/SCTySz2sT3726495OnpCY1GYzGNp9PpEB0dbXWdqKgoi/iCggJEREQ49MHYtm0bAgIC8Pjjj3cZW1dXh0uXLjl0OI2IiIjcj92pYVpaGt555x1s3boVFy5cQGpqKqqqqpCUlATg9uGjHz9cLCkpCZWVlUhLS8OFCxewdetW5ObmYsmSJaaYpqYmnD17FmfPnkVTUxMuX76Ms2fP4j//+Y9Z262trdi2bRvmzp0LDw/zyarvv/8eS5YsgV6vR0VFBQoLCzF9+nQMGTIEM2bMsHcziYiI+pS200jcWXdso93n+CQmJqKurg6rV69GdXU1wsPDkZ+fj5CQEABAdXW12T19QkNDkZ+fj9TUVGzatAlBQUHYsGGD6VJ24PbZ3A8++KDpfVZWFrKyshAbG4vCwkJT+ZEjR1BVVWX1On+5XI7S0lLs3LkTV69ehVqtxqRJk5CXlwdfX197N5OIiKhPaDt60tDQAG9vbyf3pme1ncR8J4cSHTq5OTk5GcnJyVaXbd++3aIsNjYWZ86c6bC+ESNG2JTFabXaDuO8vb1x+PDhLusgIiJyJ3K5HAMHDkRNTQ0AwMfHp0efdeUMQgg0NDSgpqYGAwcONLuU3V4OJT5ERETkOtpu3NuW/LirgQMH3vFNipn4EBER9XEymQxqtRoBAQFue5NLhUJxRzM9bZj4EBERuQm5XN4tyYE761sX/BMRERHdASY+REREJBlMfIiIiEgymPgQERGRZDDxISIiIslg4kNERESSwcSHiIiIJIP38SEiSUvfX2r2PnPmOCf1hIh6A2d8iIiISDI440NEkjG6/oRF2Rd+DzuhJ0TkLEx8iMhttT+MNdpJ/SAi18FDXURERCQZTHyIiIhIMpj4EBERkWQw8SEiIiLJYOJDREREksHEh4iIiCSDiQ8RERFJBhMfIiIikgwmPkRERCQZTHyIiIhIMpj4EBERkWQw8SEiIiLJYOJDREREksHEh4iIiCSDiQ8RERFJBhMfIiIikgwmPkRERCQZTHyIiIhIMpj4EBERkWQw8SEiIiLJYOJDREREkuFQ4rN582aEhobCy8sLGo0Gx48f7zS+qKgIGo0GXl5eCAsLQ05Ojtnyc+fOISEhASNGjIBMJkN2drZFHRkZGZDJZGYvlUplFiOEQEZGBoKCguDt7Y2JEyfi3LlzjmwiERERuSG7E5+8vDykpKRg+fLlKCkpQUxMDOLj41FVVWU1vry8HNOmTUNMTAxKSkqwbNkyLF68GPv27TPFNDQ0ICwsDGvXrrVIZn7s3nvvRXV1telVWlpqtnzdunVYv349Nm7ciNOnT0OlUiEuLg7Xr1+3dzOJiIjIDdmd+Kxfvx7z58/HggULMGbMGGRnZ2P48OHYsmWL1ficnBwEBwcjOzsbY8aMwYIFC/D8888jKyvLFDN+/Hj84Q9/wC9+8QsolcoO2/bw8IBKpTK9hg4dalomhEB2djaWL1+OmTNnIjw8HDt27EBDQwN2795t72YSERGRG/KwJ7ipqQnFxcVYunSpWblWq8XJkyetrqPX66HVas3KpkyZgtzcXBiNRigUCpvbLysrQ1BQEJRKJSIjI7FmzRqEhYUBuD2zZDAYzNpSKpWIjY3FyZMn8cILL1jU19jYiMbGRtP7+vp6AIDRaITRaLS5X9S5tn3Jfeq63HWM5GhtVyLrMsZV94G7jpE74Rg5jz373K7Ep7a2Fi0tLQgMDDQrDwwMhMFgsLqOwWCwGt/c3Iza2lqo1Wqb2o6MjMTOnTtx991345tvvsHrr7+O6OhonDt3Dv7+/qb2rbVVWVlptc7MzEysWrXKorygoAA+Pj429Ytsp9PpnN0F6oK7jdF4ebuCQZa/b8ajwux9fn6FRYwrcbcxckcco97X0NBgc6xdiU8bmcz8f01CCIuyruKtlXcmPj7e9PO4ceMQFRWFkSNHYseOHUhLS3Oob+np6Wbr1tfXY/jw4dBqtfDz87O5b9Q5o9EInU6HuLg4u2b4qPe46xit+uC82ftR9XqLmDK/KLP3K6eP7dE+Ocpdx8idcIycp+2IjS3sSnyGDBkCuVxuMbtTU1NjMdPSRqVSWY338PCAv7+/Pc2b6d+/P8aNG4eysjJTO8DtGaYfzyJ11jelUmn1nCKFQsEPbQ/gfnV97jZGLRanMYouY1x9+91tjNwRx6j32bO/7Tq52dPTExqNxmIaT6fTITo62uo6UVFRFvEFBQWIiIi4ow9GY2MjLly4YEpyQkNDoVKpzNpqampCUVFRh30jIiIiabH7UFdaWhrmzJmDiIgIREVF4a233kJVVRWSkpIA3D58dPnyZezcuRMAkJSUhI0bNyItLQ0LFy6EXq9Hbm4u9uzZY6qzqakJ58+fN/18+fJlnD17FnfddRd++tOfAgCWLFmC6dOnIzg4GDU1NXj99ddRX1+PuXPnArh9iCslJQVr1qzBqFGjMGrUKKxZswY+Pj6YPXv2ne0lIiIicgt2Jz6JiYmoq6vD6tWrUV1djfDwcOTn5yMkJAQAUF1dbXZPn9DQUOTn5yM1NRWbNm1CUFAQNmzYgISEBFPM119/jQcffND0PisrC1lZWYiNjUVhYSEA4KuvvsKzzz6L2tpaDB06FBMmTMCpU6dM7QLAK6+8gps3byI5ORlXrlxBZGQkCgoK4Ovra/eOISIiIvfj0MnNycnJSE5Otrps+/btFmWxsbE4c+ZMh/WNGDHCdMJzR/bu3dtlv2QyGTIyMpCRkdFlLBG5mYsfWikc1uvdICLXxmd1ERERkWQ4NONDRNQXjK4/4ewuEJGL4YwPERERSQYTHyIiIpIMJj5EREQkGUx8iIiISDKY+BAREZFk8KouInILO/QVzu4CEfUBnPEhIiIiyWDiQ0RERJLBxIeIiIgkg4kPERERSQZPbiYiSbN8rMU4p/SDiHoHZ3yIiIhIMpj4EBERkWQw8SEiIiLJYOJDREREksHEh4iIiCSDiQ8RERFJBhMfIiIikgwmPkRERCQZTHyIiIhIMpj4EBERkWQw8SEiIiLJYOJDREREksHEh4iIiCSDiQ8RERFJBhMfIiIikgwmPkRERCQZTHyIiIhIMpj4EBERkWQw8SEiIiLJYOJDREREksHEh4iIiCSDiQ8RERFJhkOJz+bNmxEaGgovLy9oNBocP3680/iioiJoNBp4eXkhLCwMOTk5ZsvPnTuHhIQEjBgxAjKZDNnZ2RZ1ZGZmYvz48fD19UVAQACeeuopXLx40Sxm3rx5kMlkZq8JEyY4solERETkhuxOfPLy8pCSkoLly5ejpKQEMTExiI+PR1VVldX48vJyTJs2DTExMSgpKcGyZcuwePFi7Nu3zxTT0NCAsLAwrF27FiqVymo9RUVFWLRoEU6dOgWdTofm5mZotVrcuHHDLG7q1Kmorq42vfLz8+3dRCIiInJTHvausH79esyfPx8LFiwAAGRnZ+Pw4cPYsmULMjMzLeJzcnIQHBxsmsUZM2YM/v3vfyMrKwsJCQkAgPHjx2P8+PEAgKVLl1pt96OPPjJ7v23bNgQEBKC4uBiPPPKIqVypVHaYPBEREZG02ZX4NDU1obi42CI50Wq1OHnypNV19Ho9tFqtWdmUKVOQm5sLo9EIhUJhZ5dvu3btGgBg8ODBZuWFhYUICAjAwIEDERsbizfeeAMBAQFW62hsbERjY6PpfX19PQDAaDTCaDQ61C+y1LYvuU9dl3uMkaxbanHVfeAeY+TeOEbOY88+tyvxqa2tRUtLCwIDA83KAwMDYTAYrK5jMBisxjc3N6O2thZqtdqeLgAAhBBIS0vDww8/jPDwcFN5fHw8nn76aYSEhKC8vBwrVqzA5MmTUVxcDKVSaVFPZmYmVq1aZVFeUFAAHx8fu/tFndPpdM7uAnWhL4/RwEH2/y6xxtUPj/flMZIKjlHva2hosDnW7kNdACCTmf/PSghhUdZVvLVyW7344ov47LPPcOLECbPyxMRE08/h4eGIiIhASEgIDh06hJkzZ1rUk56ejrS0NNP7+vp6DB8+HFqtFn5+fg71jSwZjUbodDrExcU5PMNHPcsdxmj3u7ndUs/s5+Z3Sz3dzR3GyN1xjJyn7YiNLexKfIYMGQK5XG4xu1NTU2Mxq9NGpVJZjffw8IC/v789zQMAXnrpJRw8eBAff/wxhg0b1mmsWq1GSEgIysrKrC5XKpVWZ4IUCgU/tD2A+9X19e0xEt1Si6tvf98eI2ngGPU+e/a3XVd1eXp6QqPRWEzj6XQ6REdHW10nKirKIr6goAARERF2dVQIgRdffBH79+/H0aNHERoa2uU6dXV1uHTpkkOH04iIiMj92H05e1paGt555x1s3boVFy5cQGpqKqqqqpCUlATg9uGjX/7yl6b4pKQkVFZWIi0tDRcuXMDWrVuRm5uLJUuWmGKamppw9uxZnD17Fk1NTbh8+TLOnj2L//znP6aYRYsWYdeuXdi9ezd8fX1hMBhgMBhw8+ZNAMD333+PJUuWQK/Xo6KiAoWFhZg+fTqGDBmCGTNmOLyDiIiIyH3YfY5PYmIi6urqsHr1alRXVyM8PBz5+fkICQkBAFRXV5vd0yc0NBT5+flITU3Fpk2bEBQUhA0bNpguZQeAr7/+Gg8++KDpfVZWFrKyshAbG4vCwkIAwJYtWwAAEydONOvPtm3bMG/ePMjlcpSWlmLnzp24evUq1Go1Jk2ahLy8PPj6+tq7mUREROSGHDq5OTk5GcnJyVaXbd++3aIsNjYWZ86c6bC+ESNGmE547khXy729vXH48OFOY4iIiEja+KwuIiIikgwmPkRERCQZTHyIiIhIMpj4EBERkWQ4dHIzEZHTXfzQ2T0goj6IMz5EREQkGZzxISL6MWszSffE934/iKhHMPEhIvqRHfoKi7K59/R+P4ioZ/BQFxEREUkGEx8iIiKSDCY+REREJBlMfIiIiEgymPgQERGRZDDxISIiIslg4kNERESSwcSHiIiIJIOJDxEREUkGEx8iIiKSDCY+REREJBlMfIiIiEgymPgQERGRZDDxISIiIslg4kNERESSwcSHiIiIJIOJDxEREUkGEx8iIiKSDCY+REREJBlMfIiIiEgymPgQERGRZDDxISIiIslg4kNERESSwcSHiIiIJIOJDxEREUkGEx8iIiKSDCY+RIRVH5w3/Zu+v9TJvSEi6jlMfIiIiEgyHEp8Nm/ejNDQUHh5eUGj0eD48eOdxhcVFUGj0cDLywthYWHIyckxW37u3DkkJCRgxIgRkMlkyM7OdqhdIQQyMjIQFBQEb29vTJw4EefOnXNkE4mIiMgN2Z345OXlISUlBcuXL0dJSQliYmIQHx+Pqqoqq/Hl5eWYNm0aYmJiUFJSgmXLlmHx4sXYt2+fKaahoQFhYWFYu3YtVCqVw+2uW7cO69evx8aNG3H69GmoVCrExcXh+vXr9m4mERERuSG7E5/169dj/vz5WLBgAcaMGYPs7GwMHz4cW7ZssRqfk5OD4OBgZGdnY8yYMViwYAGef/55ZGVlmWLGjx+PP/zhD/jFL34BpVLpULtCCGRnZ2P58uWYOXMmwsPDsWPHDjQ0NGD37t32biYRERG5IQ97gpuamlBcXIylS5ealWu1Wpw8edLqOnq9Hlqt1qxsypQpyM3NhdFohEKh6JZ2y8vLYTAYzNpSKpWIjY3FyZMn8cILL1jU29jYiMbGRtP7+vp6AIDRaITRaOyyX2Sbtn3Jfeq6+qHV7N8+MVYtol2BrMeacoX9we+R6+MYOY89+9yuxKe2thYtLS0IDAw0Kw8MDITBYLC6jsFgsBrf3NyM2tpaqNXqbmm37V9rMZWVlVbrzczMxKpVqyzKCwoK4OPj02W/yD46nc7ZXaAOaORt/94+dJyfX+G8zjho4KCuf5c4Kj8/v8fqthe/R66PY9T7GhoabI61K/FpI5OZ/89KCGFR1lW8tfLuaNeevqWnpyMtLc30vr6+HsOHD4dWq4Wfn59dfaOOGY1G6HQ6xMXF2TTDR73v9x98Do28CsUtwWhFP6ycPtbZXepamfkfl93/sn6eYXeY/dz8HqvbVvweuT6OkfO0HbGxhV2Jz5AhQyCXyy1md2pqaixmWtqoVCqr8R4eHvD39++2dttOijYYDGazSJ31TalUWj2nSKFQ8EPbA7hfXVfr/53u14p+aEG/vjFO8vb/oWl/6Kv7uNL+4PfI9XGMep89+9uuk5s9PT2h0WgspvF0Oh2io6OtrhMVFWURX1BQgIiICJs7aku7oaGhUKlUZjFNTU0oKirqsG9EREQkLXYf6kpLS8OcOXMQERGBqKgovPXWW6iqqkJSUhKA24ePLl++jJ07dwIAkpKSsHHjRqSlpWHhwoXQ6/XIzc3Fnj17THU2NTXh/Pnzpp8vX76Ms2fP4q677sJPf/pTm9qVyWRISUnBmjVrMGrUKIwaNQpr1qyBj48PZs+efWd7iYiIiNyC3YlPYmIi6urqsHr1alRXVyM8PBz5+fkICQkBAFRXV5vdWyc0NBT5+flITU3Fpk2bEBQUhA0bNiAhIcEU8/XXX+PBBx80vc/KykJWVhZiY2NRWFhoU7sA8Morr+DmzZtITk7GlStXEBkZiYKCAvj6+tq9Y4iIiMj9OHRyc3JyMpKTk60u2759u0VZbGwszpw502F9I0aMMJ3w7Gi7wO1Zn4yMDGRkZHRZFxEREUmPQ4kPEZGz7dBXOLsLRNQHMfEhssfFDy3L7onv/X4QEZFDmPgQUd9gLekkIrKTQ09nJyIiIuqLmPgQERGRZDDxISIiIslg4kNERESSwcSHiIiIJIOJDxEREUkGL2cncgbeD4iIyCk440NERESSwRkfIqKutJ+h4+wcUZ/FxIeIqAvtnwv2xblSZM4c55zOuID0/aVm76W8L6jv4aEuIiIikgwmPkRERCQZPNRF1M266zAADycQEXU/zvgQERGRZDDxISIiIslg4kNERESSwcSHiIiIJIOJDxEREUkGEx8iIiKSDF7OTiQx7S+TBwC5E/pBPcvaOLvaLRF4ywZyBs74EBERkWQw8SEiIiLJYOJDREREksFzfIjcSF84r4N6hrWxJyJLnPEhIiIiyeCMD9Gduvhhu4JhTukGkcuw+E4AuCe+9/tBZAUTH5Ku9r+c+YuZiMjtMfEh6maj60+YF1z8ikkVEZGLYOJD1BusTf13A57QSt2Kh6hIApj4EBFJBO+UTMTEh4hIstonQqPrKzA3aoRzOkPUS3g5OxEREUmGQ4nP5s2bERoaCi8vL2g0Ghw/frzT+KKiImg0Gnh5eSEsLAw5OTkWMfv27cPYsWOhVCoxduxYHDhwwGz5iBEjIJPJLF6LFi0yxcybN89i+YQJExzZRKLbLn5o/nKi9P2lFi8iIrKP3YlPXl4eUlJSsHz5cpSUlCAmJgbx8fGoqqqyGl9eXo5p06YhJiYGJSUlWLZsGRYvXox9+/aZYvR6PRITEzFnzhx8+umnmDNnDp555hl88sknppjTp0+jurra9NLpdACAp59+2qy9qVOnmsXl5+fbu4lERETkpuw+x2f9+vWYP38+FixYAADIzs7G4cOHsWXLFmRmZlrE5+TkIDg4GNnZ2QCAMWPG4N///jeysrKQkJBgqiMuLg7p6ekAgPT0dBQVFSE7Oxt79uwBAAwdOtSs3rVr12LkyJGIjY01K1cqlVCpVPZuFhERWcGZRXI3diU+TU1NKC4uxtKlS83KtVotTp48aXUdvV4PrVZrVjZlyhTk5ubCaDRCoVBAr9cjNTXVIqYtWbLWj127diEtLQ0ymcxsWWFhIQICAjBw4EDExsbijTfeQEBAgNV6Ghsb0djYaHpfX18PADAajTAajVbXIfu17UuX26ctwvy9tf61j7GJ+WfSaGsd7dqXo9WBtq1V23W9/f6vrO1fp49Vmc6GIFnXIT1EjtZe30ddfY+65/Mis/i82lKvRZ+sfeat9Lt93U7/3N0hl/1dJwH27HO7Ep/a2lq0tLQgMDDQrDwwMBAGg8HqOgaDwWp8c3MzamtroVarO4zpqM733nsPV69exbx588zK4+Pj8fTTTyMkJATl5eVYsWIFJk+ejOLiYiiVSot6MjMzsWrVKovygoIC+Pj4WG2bHNd2eNJllXXPYdGBg9Rm7/PLbPxCtmt/vLxbuoP8/Aqb69XIq6yu44ra7+feNB4VTttHHX2PuuXzMkht8XkdL6/ocjWb9oWV71f7PveFz50tXP53nRtqaGiwOdahy9nbz7IIISzKuopvX25Pnbm5uYiPj0dQUJBZeWJiounn8PBwREREICQkBIcOHcLMmTMt6klPT0daWprpfX19PYYPHw6tVgs/P78Ot4fsYzQaodPpEBcXB4VC4ezu/KD9rMKouK5jbLD7X+bnu83+r2DbVmzX/qoPztvdtjUrp4/tst5+aIVGXoXilmC0op/FOr3Ohv3efj/3pjK/qF7fR119j7rj8zKqXm/xeV31xU+6XM9iX1gbPyvfr/Z9dvrn7g657O86CWg7YmMLuxKfIUOGQC6XW8zE1NTUWMzYtFGpVFbjPTw84O/v32mMtTorKytx5MgR7N+/v8v+qtVqhISEoKyszOpypVJpdSZIoVDwQ9sDXG6/ytsl1tb61j7GJubT/Apb62jXfks33W2i/T7vrN5W9EML+jl/nGzaZ44chuweztxHHX2PuufzIiw+r7bUa9Efa+NnQ5+d/rnrJi73u04C7Nnfdn1TPD09odFoLKbxdDodoqOjra4TFRVlEV9QUICIiAhTRzuKsVbntm3bEBAQgMcff7zL/tbV1eHSpUtQq503JU5ERESuw+5DXWlpaZgzZw4iIiIQFRWFt956C1VVVUhKSgJw+/DR5cuXsXPnTgBAUlISNm7ciLS0NCxcuBB6vR65ubmmq7UA4OWXX8YjjzyCN998Ez//+c/x/vvv48iRIzhxwvxhj62trdi2bRvmzp0LDw/zrn///ffIyMhAQkIC1Go1KioqsGzZMgwZMgQzZsywe8cQuYs+cVWOk++RRETSYXfik5iYiLq6OqxevRrV1dUIDw9Hfn4+QkJCAADV1dVm9/QJDQ1Ffn4+UlNTsWnTJgQFBWHDhg2mS9kBIDo6Gnv37sVrr72GFStWYOTIkcjLy0NkZKRZ20eOHEFVVRWef/55i37J5XKUlpZi586duHr1KtRqNSZNmoS8vDz4+vrau5lERETkhhw6uTk5ORnJyclWl23fvt2iLDY2FmfOnOm0zlmzZmHWrFmdxmi1WtOJ0e15e3vj8OHDna5P5NIsZj2GOaUbrmiHvsLZXSAiN8GHlBK14eEWoi6Nrj9hpZRPeae+g4kPUQ+zNlvBJ2ATWbJ2PlrmTCZV1L2Y+BARkYlFou7nWodcmRzRnWLiQ9SHWTvs8IXfw07oCbkr64e2iPouJj5Ed8DRk27br8dDX9SX7di+xaKMn2lyVd1za1giIiKiPoCJDxEREUkGD3UREUbV64FB6tv/QgAXvwLuiXd2t4iIuh0THyKysENfgS/OmV89wytnzLW/uoj7p3PtzwPiSfjkLEx8iFyA1ZOkXewy4p6Svr8Uo+srzMp4Ymzfx7ttk6ti4kNEZCdrl3in77eM4ywQketh4kPkoniPHiLrNywkuhNMfKjvaf9MrR46CdcVHzXBm8lRd+LniaSIl7MTERGRZHDGh6SBT14nIiJwxoeIiIgkhIkPERERSQYPdRGRy+E9YIiopzDxIffUQ+f08A8ydbduuQP0xQ8tbgLJWx8QWcfEh4i6DR/j4Lp46TrRbUx8iIio19lyg07exJN6Ak9uJiIiIslg4kNERESSwcSHiIiIJIPn+FDfx7syE1ngycxE1nHGh4iIiCSDMz5EZBNeqk5E7oCJDxE5zuIw4zCndIOIyFZMfIiI+pj2s2/t79pMRB1j4kMkQZYnvsp6r/F2s0Tu8ke7/T61dqO99gkLmeMJ2dQbmPgQUY+x9oc+814ndMRJmOgQuR5e1UVERESSwRkfIjdjyyEXZ+IT7onImTjjQ0RERJLBGR8iN9dTJ4ym7y+1PDHZj5ezE5Frc2jGZ/PmzQgNDYWXlxc0Gg2OHz/eaXxRURE0Gg28vLwQFhaGnJwci5h9+/Zh7NixUCqVGDt2LA4cOGC2PCMjAzKZzOylUqnMYoQQyMjIQFBQELy9vTFx4kScO3fOkU0kIiIiN2R34pOXl4eUlBQsX74cJSUliImJQXx8PKqqqqzGl5eXY9q0aYiJiUFJSQmWLVuGxYsXY9++faYYvV6PxMREzJkzB59++inmzJmDZ555Bp988olZXffeey+qq6tNr9JS8ysm1q1bh/Xr12Pjxo04ffo0VCoV4uLicP36dXs3k4i6yej6E2Yvou6Wvr/U7EXUGbsPda1fvx7z58/HggULAADZ2dk4fPgwtmzZgszMTIv4nJwcBAcHIzs7GwAwZswY/Pvf/0ZWVhYSEhJMdcTFxSE9PR0AkJ6ejqKiImRnZ2PPnj0/dNbDw2KWp40QAtnZ2Vi+fDlmzpwJANixYwcCAwOxe/duvPDCC/ZuKrkCPoCUiIi6kV2JT1NTE4qLi7F06VKzcq1Wi5MnT1pdR6/XQ6vVmpVNmTIFubm5MBqNUCgU0Ov1SE1NtYhpS5balJWVISgoCEqlEpGRkVizZg3CwsIA3J5ZMhgMZm0plUrExsbi5MmTVhOfxsZGNDY2mt7X19cDAIxGI4xGYxd7g2zVti8d2qctopt7Y49evKmf08na/QvI0WrHep2tI6X9+APb9p8l4/l884JRcbfLf/Q9sqxbOvvYlv3qrN/fd/S7ju6IPfvcrsSntrYWLS0tCAwMNCsPDAyEwWCwuo7BYLAa39zcjNraWqjV6g5jflxnZGQkdu7cibvvvhvffPMNXn/9dURHR+PcuXPw9/c3xVqrp7Ky0mrfMjMzsWrVKovygoIC+Pj4dLAXyFE6nc7ZXbDLwEFqZ3eh1w0c9MOM6nhUdL1Cu31kdR0J7kfAxv1nRX5Zu4Iy80RIp9NhvLxdjIT2sS37NT+/65ie1Nd+17mDhoYGm2MduqpLJjP/34UQwqKsq/j25V3VGR8fb/p53LhxiIqKwsiRI7Fjxw6kpaU51Lf09HSzdevr6zF8+HBotVr4+fl1uD1kH6PRCJ1Oh7i4OCgUCvtWLnPeL5Dd/7J+3pp7kmHgIBWuXjEAuP39LPOL6nKtUfV6s/fW1mkfIxW27D9rVo6+bF4wKg6rPjiPfmiFRl6F4pZgtLY7PVNK+9iW/bpy+the6ImlO/pdR3ek7YiNLexKfIYMGQK5XG4xu1NTU2Mx09JGpVJZjffw8IC/v3+nMR3VCQD9+/fHuHHjUFZWZqoDuD3DpFb/8L+fzupRKpVQKpUW5QqFgh/aHuDQfpU7cwrfmYfZnEWgbbtH1ZsfvrZ+I0TzfdRi9XoJKe7HjvZF13b/y3yG+osvvsCPr0NpRT8rdUtnH9uyX539+5t/Q3qfPfvbrm+mp6cnNBqNxTSeTqdDdHS01XWioqIs4gsKChAREWHqaEcxHdUJ3D4/58KFC6YkJzQ0FCqVyqyepqYmFBUVdVoPERERSYfdh7rS0tIwZ84cREREICoqCm+99RaqqqqQlJQE4Pbho8uXL2Pnzp0AgKSkJGzcuBFpaWlYuHAh9Ho9cnNzza7Wevnll/HII4/gzTffxM9//nO8//77OHLkCE6c+OHS1yVLlmD69OkIDg5GTU0NXn/9ddTX12Pu3LkAbh/iSklJwZo1azBq1CiMGjUKa9asgY+PD2bPnn1HO4mkgY9SuHO8XJ2IXJ3diU9iYiLq6uqwevVqVFdXIzw8HPn5+QgJCQEAVFdXm93TJzQ0FPn5+UhNTcWmTZsQFBSEDRs2mC5lB4Do6Gjs3bsXr732GlasWIGRI0ciLy8PkZGRppivvvoKzz77LGprazF06FBMmDABp06dMrULAK+88gpu3ryJ5ORkXLlyBZGRkSgoKICvr69DO4eIiIjci0MnNycnJyM5Odnqsu3bt1uUxcbG4syZM53WOWvWLMyaNavD5Xv37u2yXzKZDBkZGcjIyOgyloiIiKSHz+oiIpvwMBYRuQMmPkREfQyTUCLHMfEh18JHVBARUQ9i4kNERG7F2oNKM2eOc0JPyBUx8SEioj6j/WE+6zfWJOqYY7cWJSIiIuqDOONDRNQDrJ2AzNkJIufjjA8RERFJBmd8iIhc2A8zRzJgkFpST2In6glMfIiInIT34yHqfTzURURERJLBGR/qPWU6QC774f098U7rCp/ETs7AGR4i52PiQ0REboX3+qHOMPEh5+HjKYiIqJcx8SEiIsnhYy2ki4kPERG5PWuJDkkTr+oiIiIiyWDiQ0RERJLBQ11ERNRn8RYBZC/O+BAREZFkMPEhIiIiyWDiQ0RERJLBc3zI7fBxFERE1BHO+BAREZFkMPEhIiIiyWDiQ0RERJLBxIeIiIgkg4kPERERSQYTHyIiIpIMJj5EREQkGUx8iIiISDKY+BAREZFk8M7NRETk1qw9wf0Lv4ed0BNyBZzxISIiIslg4kNERESS4VDis3nzZoSGhsLLywsajQbHjx/vNL6oqAgajQZeXl4ICwtDTk6ORcy+ffswduxYKJVKjB07FgcOHDBbnpmZifHjx8PX1xcBAQF46qmncPHiRbOYefPmQSaTmb0mTJjgyCYSERGRG7I78cnLy0NKSgqWL1+OkpISxMTEID4+HlVVVVbjy8vLMW3aNMTExKCkpATLli3D4sWLsW/fPlOMXq9HYmIi5syZg08//RRz5szBM888g08++cQUU1RUhEWLFuHUqVPQ6XRobm6GVqvFjRs3zNqbOnUqqqurTa/8/Hx7N5GIiIjclEwIIexZITIyEg899BC2bNliKhszZgyeeuopZGZmWsS/+uqrOHjwIC5cuGAqS0pKwqeffgq9Xg8ASExMRH19PT788ENTzNSpUzFo0CDs2bPHaj++/fZbBAQEoKioCI888giA2zM+V69exXvvvWfPJpnU19djwIABuHbtGvz8/Byqg/7PxR/G0tgikF9mxLRRCijksh5veoe+osfbcD8yDBykxtUr1QDs+pVAvYZj1J1sObk5c+Y4u+o0Go3Iz8/HtGnToFAoHO0aOcCev992XdXV1NSE4uJiLF261Kxcq9Xi5MmTVtfR6/XQarVmZVOmTEFubi6MRiMUCgX0ej1SU1MtYrKzszvsy7Vr1wAAgwcPNisvLCxEQEAABg4ciNjYWLzxxhsICAiwWkdjYyMaGxtN7+vr6wHc/vAajcYO2yYbtPzwi9n4fz8bW3rrl3XPJ1fuR9buX3I9HKPuJEdrlzH2/h1oi+ffj95nzz63K/Gpra1FS0sLAgMDzcoDAwNhMBisrmMwGKzGNzc3o7a2Fmq1usOYjuoUQiAtLQ0PP/wwwsPDTeXx8fF4+umnERISgvLycqxYsQKTJ09GcXExlEqlRT2ZmZlYtWqVRXlBQQF8fHys7wRymO7L5l5pZ+Agda+0444GDlI5uwvUBY5R9xiPii5j8vO7jrFGp9M5tB45rqGhweZYh+7jI5OZ/49DCGFR1lV8+3J76nzxxRfx2Wef4cQJ83szJCYmmn4ODw9HREQEQkJCcOjQIcycOdOinvT0dKSlpZne19fXY/jw4dBqtTzUdafKfvjiG1sEdF82Iy7Mo1cOde3+l/XzzagzMgwcpMLVKwbwMIqr4hj1pDK/KIuyldPH2lWH0WiETqdDXFwcD3X1srYjNrawK/EZMmQI5HK5xUxMTU2NxYxNG5VKZTXew8MD/v7+ncZYq/Oll17CwYMH8fHHH2PYsGGd9letViMkJARlZWVWlyuVSqszQQqFgh/aO2UlwVHIZb2S+PCPwp0Q4P5zdRyjntBi5VofR/8O8G9I77Nnf9t1VZenpyc0Go3FNJ5Op0N0dLTVdaKioiziCwoKEBERYepoRzE/rlMIgRdffBH79+/H0aNHERoa2mV/6+rqcOnSJajVPPThznboK8xeREREHbH7cva0tDS888472Lp1Ky5cuIDU1FRUVVUhKSkJwO3DR7/85S9N8UlJSaisrERaWhouXLiArVu3Ijc3F0uWLDHFvPzyyygoKMCbb76JL774Am+++SaOHDmClJQUU8yiRYuwa9cu7N69G76+vjAYDDAYDLh58yYA4Pvvv8eSJUug1+tRUVGBwsJCTJ8+HUOGDMGMGTMc3T9ERETkRuw+xycxMRF1dXVYvXo1qqurER4ejvz8fISEhAAAqqurze7pExoaivz8fKSmpmLTpk0ICgrChg0bkJCQYIqJjo7G3r178dprr2HFihUYOXIk8vLyEBkZaYppu3x+4sSJZv3Ztm0b5s2bB7lcjtLSUuzcuRNXr16FWq3GpEmTkJeXB19fX3s3k4iIiNyQ3ffxcWe8j88d+NF9e9rr6fv48PBWd+A9Ylwfx6i3zZ33G7vieR8f5+mx+/gQERFJxY7tW8zef+H3sN03NSTXw4eUEhERkWRwxofs18lhLSIid5a+v9TsPWeA+h7O+BAREZFkMPEhIiIiyeChLupTeAUXERHdCSY+5NKY6BARUXfioS4iIiKSDCY+REREJBlMfIiIiEgymPgQERGRZDDxISIiIslg4kNERESSwcvZiYiIHPTjR1jI0Yrxcid2hmzCxIeIiMgGo+tPWJR94fewE3pCd4KJD3WNDyUlIiI3wXN8iIiISDKY+BAREZFk8FAXuQw+l4uI+hrz835kwCC10/pCtmHiQ0RE1I1WfXAeLT86oJI5c5wTe0Pt8VAXERERSQZnfMgcr+AiIiI3xsSHnIbn9BCROxpVrwcgflTCQ12uhIkPERFRD9qxfYvZe2s3PeR5QL2H5/gQERGRZHDGR+p4Tg8REUkIEx/qNbv/VQXz495ERES9i4kP9QjzE5dlGMibehERkQtg4iMlPKxFREQSx8SHiIioF5k/5qINr+rqLUx8iIiInCx9f6lFGS9x7xlMfOiO8UaERETUVzDxISIicrL2h7++8HvYYhaIM0Ddg4mPO+PJzEREfZK184DS91vGMRmyHxMf6hQPYxERuS7OCtnPoUdWbN68GaGhofDy8oJGo8Hx48c7jS8qKoJGo4GXlxfCwsKQk5NjEbNv3z6MHTsWSqUSY8eOxYEDB+xuVwiBjIwMBAUFwdvbGxMnTsS5c+cc2cS+6eKH5i8iInIbo+tPmL3IMXbP+OTl5SElJQWbN2/Gz372M/zpT39CfHw8zp8/j+DgYIv48vJyTJs2DQsXLsSuXbvwz3/+E8nJyRg6dCgSEhIAAHq9HomJifj973+PGTNm4MCBA3jmmWdw4sQJREZG2tzuunXrsH79emzfvh133303Xn/9dcTFxeHixYvw9fW9k/0kGZzhISLqG2w5LwjgLFB7MiGEXc8QiIyMxEMPPYQtW3542uyYMWPw1FNPITMz0yL+1VdfxcGDB3HhwgVTWVJSEj799FPo9XoAQGJiIurr6/Hhhz/MUkydOhWDBg3Cnj17bGpXCIGgoCCkpKTg1VdfBQA0NjYiMDAQb775Jl544YUut62+vh4DBgzAtWvX4OfnZ89u6Xk9MIPTe0nO7Ts3X71SDT6ywlVxjFwfx8j1uf4YfeH3sFsmQvb8/bZrxqepqQnFxcVYunSpWblWq8XJkyetrqPX66HVas3KpkyZgtzcXBiNRigUCuj1eqSmplrEZGdn29xueXk5DAaDWVtKpRKxsbE4efKk1cSnsbERjY2NpvfXrl0DAHz33XcwGo2d7Yred+1Gp4v/WnyplzriCBk8lQ24efMWXPWXAXGMXB/HyPW5/hiF3DyCnC1HzMr+P9//smndpfGje6JL3eL69esAbp/y0hW7Ep/a2lq0tLQgMDDQrDwwMBAGg8HqOgaDwWp8c3MzamtroVarO4xpq9OWdtv+tRZTWVlptW+ZmZlYtWqVRXloaKjVeCIiIqnKcnYHbHD9+nUMGDCg0xiHruqSyWRm74UQFmVdxbcvt6XO7oppk56ejrS0NNP71tZWfPfdd/D39+90e8g+9fX1GD58OC5duuR6hxAJAMeoL+AYuT6OkfMIIXD9+nUEBQV1GWtX4jNkyBDI5XKL2Z2amhqLmZY2KpXKaryHhwf8/f07jWmr05Z2VSoVgNszP2q12mpMe0qlEkql0qxs4MCBVmPpzvn5+fGXgYvjGLk+jpHr4xg5R1czPW3supzd09MTGo0GOp3OrFyn0yE6OtrqOlFRURbxBQUFiIiIgEKh6DSmrU5b2g0NDYVKpTKLaWpqQlFRUYd9IyIiIokRdtq7d69QKBQiNzdXnD9/XqSkpIj+/fuLiooKIYQQS5cuFXPmzDHFf/nll8LHx0ekpqaK8+fPi9zcXKFQKMTf/vY3U8w///lPIZfLxdq1a8WFCxfE2rVrhYeHhzh16pTN7QohxNq1a8WAAQPE/v37RWlpqXj22WeFWq0W9fX19m4mdaNr164JAOLatWvO7gp1gGPk+jhGro9j1DfYnfgIIcSmTZtESEiI8PT0FA899JAoKioyLZs7d66IjY01iy8sLBQPPvig8PT0FCNGjBBbtmyxqPOvf/2ruOeee4RCoRCjR48W+/bts6tdIYRobW0VK1euFCqVSiiVSvHII4+I0tJSRzaRutGtW7fEypUrxa1bt5zdFeoAx8j1cYxcH8eob7D7Pj5EREREfZVDj6wgIiIi6ouY+BAREZFkMPEhIiIiyWDiQ0RERJLBxIeIiIgkg4kPdYuMjAzIZDKzV9vdtIHbtxPPyMhAUFAQvL29MXHiRJw7d86JPXZ/H3/8MaZPn46goCDIZDK89957ZsttGZPGxka89NJLGDJkCPr3748nn3wSX331VS9uhfvrapzmzZtn8d2aMGGCWQzHqedkZmZi/Pjx8PX1RUBAAJ566ilcvHjRLIbfpb6FiQ91m3vvvRfV1dWmV2lpqWnZunXrsH79emzcuBGnT5+GSqVCXFyc6Ym61P1u3LiB+++/Hxs3brS63JYxSUlJwYEDB7B3716cOHEC33//PZ544gm0tLT01ma4va7GCQCmTp1q9t3Kz883W85x6jlFRUVYtGgRTp06BZ1Oh+bmZmi1Wty4ccMUw+9SH+PUuwiR21i5cqW4//77rS5rbW0VKpVKrF271lR269YtMWDAAJGTk9NLPZQ2AOLAgQOm97aMydWrV4VCoRB79+41xVy+fFn069dPfPTRR73WdylpP05C3L4p7M9//vMO1+E49a6amhoBwHQDXX6X+h7O+FC3KSsrQ1BQEEJDQ/GLX/wCX375JQCgvLwcBoMBWq3WFKtUKhEbG4uTJ086q7uSZsuYFBcXw2g0msUEBQUhPDyc49bLCgsLERAQgLvvvhsLFy5ETU2NaRnHqXddu3YNADB48GAA/C71RUx8qFtERkZi586dOHz4MN5++20YDAZER0ejrq4OBoMBABAYGGi2TmBgoGkZ9S5bxsRgMMDT0xODBg3qMIZ6Xnx8PN59910cPXoUf/zjH3H69GlMnjwZjY2NADhOvUkIgbS0NDz88MMIDw8HwO9SX+Th7A6Qe4iPjzf9PG7cOERFRWHkyJHYsWOH6URMmUxmto4QwqKMepcjY8Jx612JiYmmn8PDwxEREYGQkBAcOnQIM2fO7HA9jlP3e/HFF/HZZ5/hxIkTFsv4Xeo7OONDPaJ///4YN24cysrKTFd3tf+fTU1NjcX/kqh32DImKpUKTU1NuHLlSocx1PvUajVCQkJQVlYGgOPUW1566SUcPHgQx44dw7Bhw0zl/C71PUx8qEc0NjbiwoULUKvVCA0NhUqlgk6nMy1vampCUVERoqOjndhL6bJlTDQaDRQKhVlMdXU1Pv/8c46bE9XV1eHSpUtQq9UAOE49TQiBF198Efv378fRo0cRGhpqtpzfpT7IeedVkzv57W9/KwoLC8WXX34pTp06JZ544gnh6+srKioqhBBCrF27VgwYMEDs379flJaWimeffVao1WpRX1/v5J67r+vXr4uSkhJRUlIiAIj169eLkpISUVlZKYSwbUySkpLEsGHDxJEjR8SZM2fE5MmTxf333y+am5udtVlup7Nxun79uvjtb38rTp48KcrLy8WxY8dEVFSU+MlPfsJx6iW/+c1vxIABA0RhYaGorq42vRoaGkwx/C71LUx8qFskJiYKtVotFAqFCAoKEjNnzhTnzp0zLW9tbRUrV64UKpVKKJVK8cgjj4jS0lIn9tj9HTt2TACweM2dO1cIYduY3Lx5U7z44oti8ODBwtvbWzzxxBOiqqrKCVvjvjobp4aGBqHVasXQoUOFQqEQwcHBYu7cuRZjwHHqOdbGBoDYtm2bKYbfpb5FJoQQvT3LREREROQMPMeHiIiIJIOJDxEREUkGEx8iIiKSDCY+REREJBlMfIiIiEgymPgQERGRZDDxISIiIslg4kNERESSwcSHiIiIJIOJDxEREUkGEx8iIiKSjP8f9bvxgTmaEb0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_histograms(x, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4bb915f5",
   "metadata": {},
   "source": [
    "> And we saw the box plots so there is no outliers, and the distribution is normal\n",
    "> \n",
    "> We will use z-score normalization, by taking a general mean and std for each of x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdc4c53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And we saw the box plots so there is no outliers, and the distribution is normal\n",
      "We will use z-score normalization\n"
     ]
    }
   ],
   "source": [
    "# print(f\"Maximun x: {max_x}, Maximum y: {max_y}, Minimum x: {min_x}, Minimum y: {min_y}\")\n",
    "print(\"And we saw the box plots so there is no outliers, and the distribution is normal\")\n",
    "x_mean = x.mean()\n",
    "y_mean = y.mean()\n",
    "x_std  = x.std()\n",
    "y_std  = y.std()\n",
    "print(\"We will use z-score normalization\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09b0204f",
   "metadata": {},
   "source": [
    "> There are many types of `rooms` but we will give them a defualt number = 1.\n",
    "> So, also we will decrease the embedings to be between 0:6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a720ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Befor: G_1 embedings are: tensor([[  0.0000, 116.3068, 141.6314],\n",
      "        [  1.0000, 181.5403, 165.1201],\n",
      "        [  3.0000, 120.7426, 100.7954],\n",
      "        [  7.0000, 132.6687, 167.8575],\n",
      "        [  7.0000, 152.0459, 100.5418],\n",
      "        [  3.0000, 192.0000, 127.0000],\n",
      "        [  2.0000,  59.5000,  55.5000]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80787/80787 [00:18<00:00, 4461.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After: G_1 embedings are: tensor([[  0.0000, 116.3068, 141.6314],\n",
      "        [  1.0000, 181.5403, 165.1201],\n",
      "        [  3.0000, 120.7426, 100.7954],\n",
      "        [  1.0000, 132.6687, 167.8575],\n",
      "        [  1.0000, 152.0459, 100.5418],\n",
      "        [  3.0000, 192.0000, 127.0000],\n",
      "        [  2.0000,  59.5000,  55.5000]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Befor: G_1 embedings are: {real_graphs_pyTorch[1].x}')\n",
    "for G in tqdm(real_graphs_pyTorch, total=len(real_graphs_pyTorch)):\n",
    "    for j ,value in enumerate(G.x):\n",
    "        type_ = int(value[0].item())\n",
    "        \n",
    "        if type_ in [1, 4, 5, 6, 7, 8]:\n",
    "            G.x[j][0] = 1\n",
    "        \n",
    "        # making all labels from 0 to 6 only to help one_hotting\n",
    "        elif type_ == 9:\n",
    "            G.x[j][0] = 4\n",
    "        elif type_ == 10:\n",
    "            G.x[j][0] = 5\n",
    "        elif type_ == 11:\n",
    "            G.x[j][0] = 6\n",
    "\n",
    "\n",
    "print(f'After: G_1 embedings are: {real_graphs_pyTorch[1].x}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be0bd6f0-db8c-4a29-a96e-b59763961295",
   "metadata": {},
   "source": [
    "> Normalization for the centroids columns & hot encoding the type one for the graphs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bdfe3bd-d1cd-4097-b755-1429dc05c890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80787/80787 [00:41<00:00, 1960.03it/s]\n"
     ]
    }
   ],
   "source": [
    "for G in tqdm(real_graphs_pyTorch, total=len(real_graphs_pyTorch)):\n",
    "    x = G.x # The feature matrix\n",
    "    for i in [1, 2]:\n",
    "        # mean = torch.mean(x[:, i])\n",
    "        # std  = torch.std(x[:, i])\n",
    "        if i == 1:\n",
    "            mean = x_mean\n",
    "            std  = x_std\n",
    "        else:\n",
    "            mean = y_mean\n",
    "            std  = y_std\n",
    "            \n",
    "        normalized_column = (x[:, i] - mean) / std\n",
    "        G.x[:, i] = normalized_column\n",
    "    \n",
    "    # One hot encoding for the first column [type of rooms]\n",
    "    first_column_encodings = F.one_hot(G.x[:, 0].long(), 7)\n",
    "    \n",
    "    G.x = torch.cat([first_column_encodings, G.x[:, 1:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36e3cfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now, we could return back to real values: tensor([116.3068, 181.5403, 120.7426, 132.6687, 152.0459, 192.0000,  59.5000],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Now, we could return back to real values: {real_graphs_pyTorch[1].x[:, -2] * x_std + x_mean}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66dc60c9",
   "metadata": {},
   "source": [
    "### All nodes to living graphs pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50a74c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 8 nodes and 7 edges\n"
     ]
    }
   ],
   "source": [
    "with open(url_all_toLiving, 'rb') as f:\n",
    "    living_graphs = pickle.load(f)\n",
    "    \n",
    "L = living_graphs[1911]\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09f8a0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80787/80787 [03:47<00:00, 355.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 10], roomType_name=[6], rec_w=[6], rec_h=[6], roomSize=[6], x=[6, 3], edge_attr=[10, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting networkx graphs to pytorchGeo graphs\n",
    "features = ['roomType_embd', 'actualCentroid_x', 'actualCentroid_y']\n",
    "living_graphs_pyTorch = []\n",
    "for G in tqdm(living_graphs):\n",
    "    G_new = from_networkx(G, group_node_attrs=features, group_edge_attrs=['distance'])\n",
    "    # Normalizing feature matrix (x)\n",
    "    # G_new = T.NormalizeFeatures()(G_new)\n",
    "    \n",
    "    living_graphs_pyTorch.append(G_new)\n",
    "\n",
    "living_graphs_pyTorch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5834412f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "getting all Xs, Ys: 100%|██████████| 80787/80787 [00:26<00:00, 3037.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(234.5, 234.0, 20.0, 20.5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = get_all_x_y(living_graphs_pyTorch)\n",
    "x.max(), y.max(), x.min(), y.min()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55a24784",
   "metadata": {},
   "source": [
    "> And we saw the box plots so there is no outliers, and the distribution is normal\n",
    "> \n",
    "> We will use z-score normalization, by taking a general mean and std for each of x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e56b6023",
   "metadata": {},
   "outputs": [],
   "source": [
    "xLiving_mean = x.mean()\n",
    "yLiving_mean = y.mean()\n",
    "xLiving_std  = x.std()\n",
    "yLiving_std  = y.std()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20192f49",
   "metadata": {},
   "source": [
    "> There are many types of `rooms` but we will give them a defualt number = 1.\n",
    "> So, also we will decrease the embedings to be between 0:6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "783abb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Befor: L_1 embedings are: tensor([[  0.0000, 116.3068, 141.6314],\n",
      "        [  1.0000, 181.5403, 165.1201],\n",
      "        [  2.0000,  59.5000,  55.5000],\n",
      "        [  3.0000, 192.0000, 127.0000],\n",
      "        [  3.0000, 120.7426, 100.7954],\n",
      "        [  7.0000, 132.6687, 167.8575],\n",
      "        [  7.0000, 152.0459, 100.5418]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80787/80787 [00:21<00:00, 3757.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After: G_1 embedings are: tensor([[  0.0000, 116.3068, 141.6314],\n",
      "        [  1.0000, 181.5403, 165.1201],\n",
      "        [  2.0000,  59.5000,  55.5000],\n",
      "        [  3.0000, 192.0000, 127.0000],\n",
      "        [  3.0000, 120.7426, 100.7954],\n",
      "        [  1.0000, 132.6687, 167.8575],\n",
      "        [  1.0000, 152.0459, 100.5418]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Befor: L_1 embedings are: {living_graphs_pyTorch[1].x}')\n",
    "for G in tqdm(living_graphs_pyTorch, total=len(living_graphs_pyTorch)):\n",
    "    for j ,value in enumerate(G.x):\n",
    "        type_ = int(value[0].item())\n",
    "        \n",
    "        if type_ in [1, 4, 5, 6, 7, 8]:\n",
    "            G.x[j][0] = 1\n",
    "        \n",
    "        # making all labels from 0 to 6 only to help one_hotting\n",
    "        elif type_ == 9:\n",
    "            G.x[j][0] = 4\n",
    "        elif type_ == 10:\n",
    "            G.x[j][0] = 5\n",
    "        elif type_ == 11:\n",
    "            G.x[j][0] = 6\n",
    "\n",
    "\n",
    "print(f'After: G_1 embedings are: {living_graphs_pyTorch[1].x}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6065a61",
   "metadata": {},
   "source": [
    "> Normalization for the centroids columns & hot encoding the type one for the graphs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f85a7da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80787/80787 [01:00<00:00, 1339.21it/s]\n"
     ]
    }
   ],
   "source": [
    "for G in tqdm(living_graphs_pyTorch, total=len(living_graphs_pyTorch)):\n",
    "    x = G.x # The feature matrix\n",
    "    for i in [1, 2]:\n",
    "        # mean = torch.mean(x[:, i])\n",
    "        # std  = torch.std(x[:, i])\n",
    "        if i == 1:\n",
    "            mean = xLiving_mean\n",
    "            std  = xLiving_std\n",
    "        else:\n",
    "            mean = yLiving_mean\n",
    "            std  = yLiving_std\n",
    "            \n",
    "        normalized_column = (x[:, i] - mean) / std\n",
    "        G.x[:, i] = normalized_column\n",
    "    \n",
    "    # One hot encoding for the first column [type of rooms]\n",
    "    first_column_encodings = F.one_hot(G.x[:, 0].long(), 7)\n",
    "    \n",
    "    G.x = torch.cat([first_column_encodings, G.x[:, 1:]], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03781d88",
   "metadata": {},
   "source": [
    "<a id='model'></a>\n",
    "## GNN Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f1cd5f8",
   "metadata": {},
   "source": [
    "<a id='dataLoader'></a>\n",
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e88277ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Planify_Dataset(Dataset):\n",
    "    def __init__(self, real_graphs, living_graphs):\n",
    "        self.real_graphs = real_graphs\n",
    "        self.living_graphs = living_graphs\n",
    "        \n",
    "        # self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.device = 'cpu'\n",
    "    def __len__(self):\n",
    "        return len(self.real_graphs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        self.adjacency_matrices = []\n",
    "        G_real   = self.real_graphs[index].clone().to(self.device)\n",
    "        G_living = self.living_graphs[index].clone().to(self.device) \n",
    "        # shuffling nodes inside the same graph\n",
    "        # permutation = torch.randperm(G.num_nodes).to(self.device)\n",
    "        \n",
    "        # G.x = G.x[permutation]\n",
    "        # G.edge_index = permutation[G.edge_index]\n",
    "        # G.rec_w = G.rec_w[permutation]\n",
    "        # G.rec_h = G.rec_h[permutation]\n",
    "        # G.edge_attr = G.edge_attr[permutation]\n",
    "        \n",
    "        nu_nodes = G_real.x.shape[0]\n",
    "        \n",
    "        # padded_x = torch.nn.functional.pad(G.x, pad=(0, 0, 0, 8 - nu_nodes), mode='constant', value=0)\n",
    "        # padded_y = torch.nn.functional.pad(y, pad=(0, 8 - nu_nodes), mode='constant', value=0)\n",
    "        \n",
    "        edge_index = G_real.edge_index\n",
    "        real_adj_matrix = torch.zeros((nu_nodes, nu_nodes), dtype=torch.float32)\n",
    "        \n",
    "        # Set the values in the adjacency matrix to 1 where there are edges in the graph\n",
    "        real_adj_matrix[edge_index[0], edge_index[1]] = 1\n",
    "        real_adj_matrix[edge_index[1], edge_index[0]] = 1  # if the graph is undirected\n",
    "        \n",
    "        \n",
    "        # Creating a new graph with comming data from the living graphs with the adj matrix of the real graph we need.\n",
    "        # data = Data(x=G_living.x, edge_index=G_living.edge_index, edge_attr=G_living.edge_attr, target_adj=real_adj_matrix)\n",
    "        \n",
    "        # Considering only the upeer half of the matrix (including the diagonal)\n",
    "        # adj_matrix = torch.triu(adj_matrix).squeeze()\n",
    "        \n",
    "        # data = {\n",
    "        #     'x_living'  : G_living.x.to(torch.float32),\n",
    "        #     'edge_index_living': G_living.edge_index,\n",
    "        #     'edge_attr_living': G_living.edge_attr,\n",
    "            \n",
    "        #     'edge_attr_real': G_real.edge_attr,\n",
    "            \n",
    "        # }\n",
    "        data = {\n",
    "            'G_living': G_living,\n",
    "            'adj': real_adj_matrix.to(self.device)\n",
    "        }\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "52291edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_adj(G_real):\n",
    "    \"\"\"\n",
    "    This function will be used inside the training loop to get the real adj matrix of indexed graph\n",
    "    Inputs:\n",
    "        G_real: a graph represents the real graph to get its adj matrix.\n",
    "    \"\"\"\n",
    "    nu_nodes = G_real.x.shape[0]\n",
    "    \n",
    "    edge_index = G_real.edge_index\n",
    "    real_adj_matrix = torch.zeros((nu_nodes, nu_nodes), dtype=torch.float32)\n",
    "    \n",
    "    # Set the values in the adjacency matrix to 1 where there are edges in the graph\n",
    "    real_adj_matrix[edge_index[0], edge_index[1]] = 1\n",
    "    real_adj_matrix[edge_index[1], edge_index[0]] = 1  # if the graph is undirected\n",
    "    \n",
    "    return real_adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e63bf5fe-ce1a-47f6-a92f-c59c77e499f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge = int(len(real_graphs_pyTorch) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0f01bd03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_dataset = Planify_Dataset(real_graphs_pyTorch[:edge], living_graphs_pyTorch[:edge])\n",
    "train_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "val_dataset = Planify_Dataset(real_graphs_pyTorch[edge: -10], living_graphs_pyTorch[edge: -10])\n",
    "val_loader  = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = Planify_Dataset(real_graphs_pyTorch[-10:], living_graphs_pyTorch[-10:])\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fc7e7933-6d23-4d0a-b4e2-baa43bc561a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model function\n",
    "import os\n",
    "\n",
    "# checkpoint_dir = '/kaggle/working/checkpoints'\n",
    "# checkpoint_dir = '/media/mo/DATA/Grad/Planify_Dataset/Graph/checkpoints'\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "    \n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch):\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch.pt')\n",
    "    # Saving model each 15 epochs\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'epoch': epoch\n",
    "    }, checkpoint_path)\n",
    "    \n",
    "    print('Model saved :)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "111ed4e1",
   "metadata": {},
   "source": [
    "<a id='archi'></a>\n",
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7692bf9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): GCNConv(9, 256)\n",
       "  (conv2): GCNConv(256, 9)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "    \n",
    "    def encoder(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "    \n",
    "    def decoder(self, z, edge_index):\n",
    "        # z = z.sigmoid()\n",
    "        return (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)\n",
    "    \n",
    "    # def forward(self, x, edge_index):\n",
    "    #     z = self.encoder(x, edge_index)\n",
    "    #     prob_adj = z @ z.t()\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        # return (prob_adj > 0).nonzero(as_tuple=False)\n",
    "        return prob_adj\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        z = self.encoder(x, edge_index)\n",
    "        return self.decode_all(z)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "model = Net(in_channels=9, hidden_channels=256, out_channels=9).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b3def3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GraphEncoder(nn.Module):\n",
    "#     def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "#         super(GraphEncoder, self).__init__()\n",
    "#         self.conv1 = GATConv(in_channels, hidden_channels, heads=4)\n",
    "#         self.conv2 = GATConv(hidden_channels*4, hidden_channels, heads=4)\n",
    "#         self.conv3 = GATConv(hidden_channels*4, out_channels)\n",
    "    \n",
    "#     def forward(self, x, edge_index):\n",
    "#         \"\"\"\n",
    "#         x: feature matrix of shape [num_nodes, num_features]\n",
    "#         edge_index: all nodes to living graphs' edge index matrix of shape [2, num_edges]\n",
    "        \n",
    "#         \"\"\"\n",
    "#         x = F.relu(self.conv1(x, edge_index))\n",
    "#         x = F.dropout(x, p=0.15, training=self.training)\n",
    "#         x = F.relu(self.conv2(x, edge_index))\n",
    "#         x = F.dropout(x, p=0.15, training=self.training)\n",
    "#         x = self.conv3(x, edge_index)\n",
    "        \n",
    "#         return x\n",
    "\n",
    "# class GraphDecoder(nn.Module):\n",
    "#     def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "#         super(GraphDecoder, self).__init__()\n",
    "#         self.conv1 = GATConv(in_channels, hidden_channels, heads=4)\n",
    "#         self.conv2 = GATConv(hidden_channels*4, hidden_channels, heads=4)\n",
    "#         self.conv3 = GATConv(hidden_channels*4, out_channels)\n",
    "    \n",
    "#     def forward(self, x, edge_index):\n",
    "#         \"\"\"\n",
    "#         x: feature matrix of shape [num_nodes, num_features]\n",
    "#         edge_index: all nodes to living graphs' edge index matrix of shape [2, num_edges]\n",
    "        \n",
    "#         \"\"\"\n",
    "#         x = F.relu(self.conv1(x, edge_index))\n",
    "#         x = F.dropout(x, p=0.15, training=self.training)\n",
    "#         x = F.relu(self.conv2(x, edge_index))\n",
    "#         x = F.dropout(x, p=0.15, training=self.training)\n",
    "#         x = self.conv3(x, edge_index)\n",
    "        \n",
    "#         x = torch.matmul(x, x.T)\n",
    "#         x = torch.sigmoid(x)\n",
    "        \n",
    "        \n",
    "#         return x\n",
    "\n",
    "# class GraphAutoEncoder(nn.Module):\n",
    "#     def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "#         super(GraphAutoEncoder, self).__init__()\n",
    "#         self.encoder = GraphEncoder(in_channels, hidden_channels, out_channels)\n",
    "#         self.decoder = GraphDecoder(out_channels, hidden_channels, in_channels)\n",
    "        \n",
    "#     def forward(self, graph):\n",
    "#         x, edge_index, batch = graph.x.to(torch.float32), graph.edge_index, graph.batch\n",
    "#         z = self.encoder(x, edge_index)\n",
    "#         adj = self.decoder(z, edge_index)\n",
    "\n",
    "#         return adj\n",
    "\n",
    "# nu_features = real_graphs_pyTorch[0].x.shape[1]\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = GraphAutoEncoder(nu_features, 64, nu_features).to(device)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "36e19668",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "critereon = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# optimizer = optimizer.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "18d7197b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 300/64629 [00:01<06:56, 154.51it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      3\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm(train_loader, total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(train_loader)):\n\u001b[0;32m      6\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m      8\u001b[0m     living_graphs \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mG_living\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\zmlka\\anaconda3\\envs\\torch2\\lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zmlka\\anaconda3\\envs\\torch2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\zmlka\\anaconda3\\envs\\torch2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\zmlka\\anaconda3\\envs\\torch2\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\zmlka\\anaconda3\\envs\\torch2\\lib\\site-packages\\torch_geometric\\loader\\dataloader.py:31\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m batch\n\u001b[0;32m     30\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, Mapping):\n\u001b[1;32m---> 31\u001b[0m     \u001b[39mreturn\u001b[39;00m {key: \u001b[39mself\u001b[39m([data[key] \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m batch]) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n\u001b[0;32m     32\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(elem, \u001b[39m'\u001b[39m\u001b[39m_fields\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     33\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(elem)(\u001b[39m*\u001b[39m(\u001b[39mself\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)))\n",
      "File \u001b[1;32mc:\\Users\\zmlka\\anaconda3\\envs\\torch2\\lib\\site-packages\\torch_geometric\\loader\\dataloader.py:31\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m batch\n\u001b[0;32m     30\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, Mapping):\n\u001b[1;32m---> 31\u001b[0m     \u001b[39mreturn\u001b[39;00m {key: \u001b[39mself\u001b[39;49m([data[key] \u001b[39mfor\u001b[39;49;00m data \u001b[39min\u001b[39;49;00m batch]) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n\u001b[0;32m     32\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(elem, \u001b[39m'\u001b[39m\u001b[39m_fields\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     33\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(elem)(\u001b[39m*\u001b[39m(\u001b[39mself\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)))\n",
      "File \u001b[1;32mc:\\Users\\zmlka\\anaconda3\\envs\\torch2\\lib\\site-packages\\torch_geometric\\loader\\dataloader.py:20\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     18\u001b[0m elem \u001b[39m=\u001b[39m batch[\u001b[39m0\u001b[39m]\n\u001b[0;32m     19\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, BaseData):\n\u001b[1;32m---> 20\u001b[0m     \u001b[39mreturn\u001b[39;00m Batch\u001b[39m.\u001b[39;49mfrom_data_list(batch, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfollow_batch,\n\u001b[0;32m     21\u001b[0m                                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexclude_keys)\n\u001b[0;32m     22\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m     23\u001b[0m     \u001b[39mreturn\u001b[39;00m default_collate(batch)\n",
      "File \u001b[1;32mc:\\Users\\zmlka\\anaconda3\\envs\\torch2\\lib\\site-packages\\torch_geometric\\data\\batch.py:76\u001b[0m, in \u001b[0;36mBatch.from_data_list\u001b[1;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_data_list\u001b[39m(\u001b[39mcls\u001b[39m, data_list: List[BaseData],\n\u001b[0;32m     66\u001b[0m                    follow_batch: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     67\u001b[0m                    exclude_keys: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     68\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[39m    Python list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39m    :obj:`follow_batch`.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[39m    Will exclude any keys given in :obj:`exclude_keys`.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m     batch, slice_dict, inc_dict \u001b[39m=\u001b[39m collate(\n\u001b[0;32m     77\u001b[0m         \u001b[39mcls\u001b[39;49m,\n\u001b[0;32m     78\u001b[0m         data_list\u001b[39m=\u001b[39;49mdata_list,\n\u001b[0;32m     79\u001b[0m         increment\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     80\u001b[0m         add_batch\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(data_list[\u001b[39m0\u001b[39;49m], Batch),\n\u001b[0;32m     81\u001b[0m         follow_batch\u001b[39m=\u001b[39;49mfollow_batch,\n\u001b[0;32m     82\u001b[0m         exclude_keys\u001b[39m=\u001b[39;49mexclude_keys,\n\u001b[0;32m     83\u001b[0m     )\n\u001b[0;32m     85\u001b[0m     batch\u001b[39m.\u001b[39m_num_graphs \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data_list)\n\u001b[0;32m     86\u001b[0m     batch\u001b[39m.\u001b[39m_slice_dict \u001b[39m=\u001b[39m slice_dict\n",
      "File \u001b[1;32mc:\\Users\\zmlka\\anaconda3\\envs\\torch2\\lib\\site-packages\\torch_geometric\\data\\collate.py:84\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[39m# Collate attributes into a unified representation:\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m value, slices, incs \u001b[39m=\u001b[39m _collate(attr, values, data_list, stores,\n\u001b[0;32m     85\u001b[0m                                increment)\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, Tensor) \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mis_cuda:\n\u001b[0;32m     88\u001b[0m     device \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mdevice\n",
      "File \u001b[1;32mc:\\Users\\zmlka\\anaconda3\\envs\\torch2\\lib\\site-packages\\torch_geometric\\data\\collate.py:131\u001b[0m, in \u001b[0;36m_collate\u001b[1;34m(key, values, data_list, stores, increment)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39mif\u001b[39;00m cat_dim \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m elem\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    130\u001b[0m     values \u001b[39m=\u001b[39m [value\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m) \u001b[39mfor\u001b[39;00m value \u001b[39min\u001b[39;00m values]\n\u001b[1;32m--> 131\u001b[0m slices \u001b[39m=\u001b[39m cumsum([value\u001b[39m.\u001b[39;49msize(cat_dim \u001b[39mor\u001b[39;49;00m \u001b[39m0\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m value \u001b[39min\u001b[39;49;00m values])\n\u001b[0;32m    132\u001b[0m \u001b[39mif\u001b[39;00m increment:\n\u001b[0;32m    133\u001b[0m     incs \u001b[39m=\u001b[39m get_incs(key, values, data_list, stores)\n",
      "File \u001b[1;32mc:\\Users\\zmlka\\anaconda3\\envs\\torch2\\lib\\site-packages\\torch_geometric\\data\\collate.py:256\u001b[0m, in \u001b[0;36mcumsum\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m    254\u001b[0m out \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mnew_empty((value\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, ) \u001b[39m+\u001b[39m value\u001b[39m.\u001b[39msize()[\u001b[39m1\u001b[39m:])\n\u001b[0;32m    255\u001b[0m out[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m--> 256\u001b[0m torch\u001b[39m.\u001b[39;49mcumsum(value, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout[\u001b[39m1\u001b[39;49m:])\n\u001b[0;32m    257\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epochs in range(10):\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for batch in tqdm(train_loader, total=len(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        living_graphs = batch['G_living']\n",
    "        # real_graphs  = batch['G_real']\n",
    "        \n",
    "        x = living_graphs.x.to(torch.float32)\n",
    "        edge_index_living = living_graphs.edge_index\n",
    "\n",
    "        pred_adj = model(living_graphs.x.to(torch.float32), living_graphs.edge_index)\n",
    "        # real_adj_matrices = []\n",
    "        # for idx in real_graphs.batch.unique():\n",
    "        #     adj = get_real_adj(real_graphs[idx]).flatten()\n",
    "        #     real_adj_matrices.append(adj)\n",
    "        \n",
    "        # real_adj = torch.cat(real_adj_matrices)\n",
    "        real_adj = batch['adj'].squeeze()\n",
    "        loss = critereon(pred_adj.flatten(), real_adj.flatten())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    print(train_loss / len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "159fa30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    living_graphs = batch['G_living']\n",
    "        # real_graphs  = batch['G_real']\n",
    "        \n",
    "    x = living_graphs.x.to(torch.float32)\n",
    "    edge_index_living = living_graphs.edge_index\n",
    "\n",
    "    pred_adj = model(living_graphs.x.to(torch.float32), living_graphs.edge_index)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8a208e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_loader):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, batch in tqdm(enumerate(train_loader), desc=\"Planifying\", total=len(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        living_graphs = batch['G_living']\n",
    "        # real_graphs  = batch['G_real']\n",
    "        \n",
    "        x = living_graphs.x.to(torch.float32)\n",
    "        edge_index_living = living_graphs.edge_index\n",
    "\n",
    "        pred_adj = model(x, edge_index_living).flatten()\n",
    "        real_adj = batch['adj'].flatten()\n",
    "        \n",
    "        loss = criterion(pred_adj, real_adj)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Monitoring\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "    \n",
    "def evaluate(model, criterion, val_loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            living_graphs = batch['G_living']\n",
    "        # real_graphs  = batch['G_real']\n",
    "\n",
    "            x = living_graphs.x.to(torch.float32)\n",
    "            edge_index_living = living_graphs.edge_index\n",
    "\n",
    "            pred_adj = model(x, edge_index_living).flatten()\n",
    "            real_adj = batch['adj'].flatten()\n",
    "\n",
    "            loss = criterion(pred_adj, real_adj)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "    return running_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4dd954fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "patience = 10 # Number of epochs to wait if validation loss doesn't improve\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "counter = 0\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=3e-4)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.950)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b7ec9799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "271a7b40",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='train'></a>\n",
    "### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d9a39a37-e8b9-46f1-b39a-09c57295a46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Planifying: 100%|██████████| 64629/64629 [08:52<00:00, 121.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating ...\n",
      "Epoch [1/5], Train Loss: 0.6693, Validation Loss: 0.6684\n",
      "Model saved :)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Planifying: 100%|██████████| 64629/64629 [09:06<00:00, 118.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating ...\n",
      "Epoch [2/5], Train Loss: 0.6692, Validation Loss: 0.6684\n",
      "Model saved :)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Planifying: 100%|██████████| 64629/64629 [08:29<00:00, 126.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating ...\n",
      "Epoch [3/5], Train Loss: 0.6691, Validation Loss: 0.6683\n",
      "Model saved :)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Planifying: 100%|██████████| 64629/64629 [06:57<00:00, 154.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating ...\n",
      "Epoch [4/5], Train Loss: 0.6691, Validation Loss: 0.6683\n",
      "Model saved :)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Planifying:   4%|▍         | 2432/64629 [00:27<11:37, 89.13it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[122], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m      2\u001b[0m     \u001b[39m# Training loop\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     train_loss \u001b[39m=\u001b[39m train(model, optimizer, criterion, train_loader)\n\u001b[0;32m      4\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(train_loss)\n\u001b[0;32m      6\u001b[0m     \u001b[39m# Evaluation loop\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[119], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, criterion, train_loader)\u001b[0m\n\u001b[0;32m     10\u001b[0m x \u001b[39m=\u001b[39m living_graphs\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m     11\u001b[0m edge_index_living \u001b[39m=\u001b[39m living_graphs\u001b[39m.\u001b[39medge_index\n\u001b[1;32m---> 13\u001b[0m pred_adj \u001b[39m=\u001b[39m model(x, edge_index_living)\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m     14\u001b[0m real_adj \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39madj\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m     16\u001b[0m loss \u001b[39m=\u001b[39m criterion(pred_adj, real_adj)\n",
      "File \u001b[1;32mc:\\Users\\zmlka\\anaconda3\\envs\\torch2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[72], line 26\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, edge_index):\n\u001b[1;32m---> 26\u001b[0m     z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x, edge_index)\n\u001b[0;32m     27\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecode_all(z)\n",
      "Cell \u001b[1;32mIn[72], line 10\u001b[0m, in \u001b[0;36mNet.encoder\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m      8\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x, edge_index)\n\u001b[0;32m      9\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mrelu()\n\u001b[1;32m---> 10\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x, edge_index)\n\u001b[0;32m     11\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\zmlka\\anaconda3\\envs\\torch2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\zmlka\\anaconda3\\envs\\torch2\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:232\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    229\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin(x)\n\u001b[0;32m    231\u001b[0m \u001b[39m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49mx, edge_weight\u001b[39m=\u001b[39;49medge_weight,\n\u001b[0;32m    233\u001b[0m                      size\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    235\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    236\u001b[0m     out \u001b[39m=\u001b[39m out \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\n",
      "File \u001b[1;32mc:\\Users\\zmlka\\anaconda3\\envs\\torch2\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:467\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[1;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[0;32m    465\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    466\u001b[0m         msg_kwargs \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m res\n\u001b[1;32m--> 467\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmessage(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmsg_kwargs)\n\u001b[0;32m    468\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_forward_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m    469\u001b[0m     res \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, (msg_kwargs, ), out)\n",
      "File \u001b[1;32mc:\\Users\\zmlka\\anaconda3\\envs\\torch2\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:241\u001b[0m, in \u001b[0;36mGCNConv.message\u001b[1;34m(self, x_j, edge_weight)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmessage\u001b[39m(\u001b[39mself\u001b[39m, x_j: Tensor, edge_weight: OptTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 241\u001b[0m     \u001b[39mreturn\u001b[39;00m x_j \u001b[39mif\u001b[39;00m edge_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m edge_weight\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m) \u001b[39m*\u001b[39m x_j\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # Training loop\n",
    "    train_loss = train(model, optimizer, criterion, train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Evaluation loop\n",
    "    print('Validating ...')\n",
    "    val_loss = evaluate(model, criterion, val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # Printing and monitoring\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "    \n",
    "    \n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = deepcopy(model)\n",
    "        save_checkpoint(best_model, optimizer, epoch)\n",
    "        counter = 0\n",
    "        \n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f'Validation loss did not improve for {patience} epochs. Stopping early.')\n",
    "            break\n",
    "        if counter in range(2, 20, 2):\n",
    "            scheduler.step()\n",
    "            print(f\"Learning rate decreased!, now is {optimizer.state_dict()['param_groups'][0]['lr']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af042441",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=f'Best training    loss: {min(train_losses):.0f}');\n",
    "plt.plot(val_losses, label=f'Best validation loss: {min(val_losses):.0f}');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e17936",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in train_loader:\n",
    "    G = l['G']\n",
    "    adj = l['adj']\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
